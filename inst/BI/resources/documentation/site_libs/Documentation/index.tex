% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={BI documentation},
  pdfauthor={Sebastian Sosa},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{BI documentation}
\author{Sebastian Sosa}
\date{2024-09-09}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter{}\label{section}

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

\section{1.1 Model set-up}\label{model-set-up}

We define a likelihood (e.g., a mathematical formula that specifies the
plausibility of the data). The likelihood has parameters (e.g.,
adjustable inputs) for which we define priors (e.g., initial
plausibility assignment for each possible value of the parameter).
Considering a linear regression with an intercept (e.g., \(Œº\) value
when \(x\) is at zero, or at the mean if the data is centered), a slope
(e.g., \(Œº\) change value when \(x\) is incremented by one unit), and
assuming the data is centered ({ as we will always concider in the next
chapters}):

{ * Toolpit available for each lines of equation }

\href{bi/doc/0.\%20\%Introduction.md}{\[y \sim  Normal(Œº,œÉ)
\]}

\href{bi/doc/0.\%20\%Introduction.md}{\[ Œº \sim Œ± + Œ≤x
\]}

\href{bi/doc/0.\%20\%Introduction.md}{\[ Œ± \sim Normal(0,1)
\]}

\href{bi/doc/0.\%20\%Introduction.md}{\[ Œ≤ \sim Normal(0,1)
\]}

\href{bi/doc/0.\%20\%Introduction.md}{\[ œÉ \sim Uniform(0,1)
\]}

\section{1.2 Model fitting}\label{model-fitting}

By using probability distributions for parameters, we can better tune
the model by describing parameters with `\emph{subequations}' and
accounting for \emph{correlated varying effects}, \emph{Gaussian
processes}, \emph{measurement error}, and \emph{missing data}.

In addition, we can use \emph{Bayesian updating} using the
\emph{Bayesian theorem} to `reshape' the prior distributions by
considering every possible combination of values for ¬µ and œÉ and scoring
each combination by its relative plausibility in light of the data.
These relative plausibilities are the posterior probabilities of each
combination of values ¬µ and œÉ: the \emph{posterior distributions}.
Various techniques can be used to approximate the mathematics that
follows from the definition of Bayes' theorem: grid approximation,
quadratic approximation, and Markov chain Monte Carlo (\emph{MCMC}).

\hyperref[]{\[\frac{likelihood*Priors}{average likelihood}\]}

\section{1.3 Model `diagnostic'}\label{model-diagnostic}

The posterior distribution can be described using percentile intervals
(\emph{PI}), the highest posterior density interval (\emph{HPDI}), and
point estimates. We can also sample the posterior distribution and
generate \emph{dummy data}, which can help check the model through
\emph{observations and p uncertainty propagation on the samples}. In
some aspects, it is the opposite of a null model as it represents an
expected model.

\section{1.4 Link functions}\label{link-functions}

We will see different families of regreessions that have different
distribtions. For the moment we just need to know that those different
distribtions required \_link function (for each specific family we will
discuss the corresponding link function):

\section{Vocabulary}\label{vocabulary}

This method evaluate if variable we want to predict -the dependent
variable (\emph{Y})- and the variable(s) that may affect(s)-independent
variables (\emph{Xs})- this dependent variable is

\section{Conciderations}\label{conciderations}

When implementing Bayesian linear regression with TensorFlow
Probability, it's important to consider the following: - Specifying
appropriate prior distributions for the model parameters. - Choosing an
appropriate likelihood function that captures the relationship between
the inputs and outputs. - Selecting an inference method to approximate
the posterior distribution over parameters, such as Markov chain Monte
Carlo (MCMC) or variational inference.

\bookmarksetup{startatroot}

\chapter{Linear Regression for continuous
variable}\label{linear-regression-for-continuous-variable}

\section{General Principles}\label{general-principles}

To study relationships between two continuous variables (e.g., height
and weight), we can use a \emph{Linear regression approach}. Basically,
we draw a line that crosses the point cloud of the two tested variables.
For this, we need to have: 1) an intercept \(\alpha\), which represents
origin of the line, 2) a coefficient \(\beta\), which informs us about
the slope of the line, and 3) an variance term \(\sigma\), which informs
us about the spread of points around the line. We can interpret the
intercept \(\alpha\) as the expected value of the dependent variable
when all independent variables are equal to zero, the coefficient
\(\beta\) as how much \emph{Y} increases for each increment of \emph{X},
and \(\sigma\) as the varrance around the prediction.

\includegraphics{index_files/mediabag/1-WCcaObzvvVzcrg8CBi.webp}

\section{Considerations}\label{considerations}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  Bayesian linear regression considers uncertainty in the model
  parameters and provides a full posterior distribution over them. We
  thus need to declare prior distributions for \(\alpha\), \(\beta\),
  and \(\sigma^2\).
\item
  Usually, we use a \emph{Normal} distribution for \(\alpha\) and
  \(\beta\), and an \emph{exponential} or \emph{Gamma} distribution for
  \(\sigma\) (basically any distribution that is positively defined).
\item
  As we consider that data is standardized (see introduction), we use a
  distribution with a mean of 0 and a standard deviation of 1.
\item
  \(\sigma\) is assumed to be strictly positive.
\item
  Gaussian regression deals directly with continuous outcomes,
  estimating a linear relationship between predictors and the outcome
  variable without needing a link function. This simplifies
  interpretation, as coefficients represent direct changes in the
  outcome variable.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example}

Below is an example code snippet demonstrating Bayesian linear
regression using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ .bi.main }\ImportTok{import}\OperatorTok{*}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/Howell1.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.df }\OperatorTok{=}\NormalTok{ m.df[m.df.age }\OperatorTok{\textgreater{}} \DecValTok{18}\NormalTok{]}
\NormalTok{m.scale([}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{])}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}height\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(height, weight):    }
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{178}\NormalTok{, }\DecValTok{20}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{)   }
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ dist.uniform(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    lk(}\StringTok{"height"}\NormalTok{, Normal(alpha }\OperatorTok{+}\NormalTok{ beta }\OperatorTok{*}\NormalTok{ weight, sigma), obs }\OperatorTok{=}\NormalTok{ height)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\FunctionTok{setwd}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\FunctionTok{getwd}\NormalTok{(), }\StringTok{\textquotesingle{}/bi\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}
\FunctionTok{load}\NormalTok{(}\StringTok{\textquotesingle{}STRAND sim sr dyad.Rdata\textquotesingle{}}\NormalTok{)}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/Howell1.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\NormalTok{df }\OtherTok{=}\NormalTok{ m}\SpecialCharTok{$}\NormalTok{df[m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{age }\SpecialCharTok{\textgreater{}} \DecValTok{18}\NormalTok{,]}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{scale}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}height\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(height, weight)\{}
\NormalTok{  s }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{uniform}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}s\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  a }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{178}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  b }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))   }
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Normal}\NormalTok{(a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ weight, s), }\AttributeTok{obs =}\NormalTok{ height)}
\NormalTok{\}}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation}

The following equation allows us to draw a line and is the one that is
most used in statistics classes: \[
Y_i = \alpha + \beta  X_i + \epsilon_i
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression coefficient.
\item
  \(X_i\) is the input variable for observation \emph{i}.
\item
  \(\epsilon_i\) is a vector of error terms, independently distributed.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express a Bayesian
version of this regression model using the following model:

\[
Y_i \sim Normal(\alpha + \beta   X_i, \sigma)
\]

\[
\alpha \sim Normal(0, 1)
\]

\[
\beta \sim Normal(0, 1)
\]

\[
\sigma \sim Uniform(0, 50)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\beta\) and \(\alpha\) are the regression coefficients and intercept
  parameters, respectively.
\item
  \(X_i\) is the input variable for observation \emph{i}.
\item
  \(\sigma\) is a prior for the vairance term standard deviation of the
  normal distribution that describes the variance in the relationship
  between the dependent variable \(Y\) and the independent variable
  \(X\).
\end{itemize}

\section{Reference(s)}\label{references}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Multiple continuous variables
model}\label{multiple-continuous-variables-model}

\section{General Principles}\label{general-principles-1}

To study relationships between multiple continuous variables (e.g., the
effect of height and age on weight), we can use a Multiple Regression
approach. Essentially, we extend the
\href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Linear
Regression for continuous variable} by adding a regression coefficient
\(\beta\) for each continuous variable.

\includegraphics{index_files/mediabag/0-dJqdzk1aMo2OQR7O.pdf}

\section{Considerations}\label{considerations-1}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  We need a regression coefficient \(\beta\) for each independent
  variable.
\item
  Model interpretation of the regression coefficients \(\beta\) is
  considered for a fixed value of the other dependent variables'
  regression coefficients---i.e., for a given age, a variation of 1 unit
  in height reflects the value of the regression coefficient \(\beta\)
  for height.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-1}

Below is an example code snippet demonstrating Bayesian multiple
regression using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/Howell1.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.df }\OperatorTok{=}\NormalTok{ m.df[m.df.age }\OperatorTok{\textgreater{}} \DecValTok{18}\NormalTok{]}
\NormalTok{m.scale([}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{])}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}height\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(height, weight, age):}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)    }
\NormalTok{    beta1 }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}beta1\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta2 }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}beta2\textquotesingle{}}\NormalTok{)}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ bi.dist.uniform(}\DecValTok{0}\NormalTok{,}\DecValTok{50}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}

\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Normal(alpha }\OperatorTok{+}\NormalTok{ beta1 }\OperatorTok{*}\NormalTok{ weight }\OperatorTok{+}\NormalTok{ beta2 }\OperatorTok{*}\NormalTok{ age, sigma), obs}\OperatorTok{=}\NormalTok{height)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/Howell1.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\NormalTok{df }\OtherTok{=}\NormalTok{ m}\SpecialCharTok{$}\NormalTok{df[m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{age }\SpecialCharTok{\textgreater{}} \DecValTok{18}\NormalTok{,]}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{scale}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}weight\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}height\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(height, weight, age)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  beta1 }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b1\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  beta2 }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(  }\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b2\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))   }
\NormalTok{  sigma }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{uniform}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}s\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Normal}\NormalTok{(alpha }\SpecialCharTok{+}\NormalTok{ beta1 }\SpecialCharTok{*}\NormalTok{ weight }\SpecialCharTok{+}\NormalTok{ beta2 }\SpecialCharTok{*}\NormalTok{ age, sigma), }\AttributeTok{obs=}\NormalTok{height)}
\NormalTok{\}}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-1}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-1}

We model the relationship between the independent variables
\((X_1, X_2, ..., X_n)\) and the dependent variable \emph{Y} using the
following equation:

\[
ùëå_i = \alpha +\beta_1  ùëã_{1i} + \beta_2  ùëã_{2i} + ... + \beta_n  ùëã_{1n} + \sigma
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(X_{1i}\), \(X_{2i}\), \ldots, \(X_{1n}\) are the values of the
  independent variables for observation \emph{i}.
\item
  \(\beta_1\), \(\beta_2\), \ldots, \(\beta_n\) are the regression
  coefficients.
\item
  \(\sigma\) is the error term.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-1}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
model as follows:

\[
ùëå \sim Normal(\alpha + \sum_k^n  \beta_k  X, œÉ¬≤)
\]

\[
\alpha \sim Normal(0,1)
\]

\[
\beta_i \sim Normal(0,1)
\]

\[
œÉ \sim Uniform(0, 50)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the prior distribution for the intercept.
\item
  \(\beta_k\) are the prior distributions for the regression
  coefficients \emph{k} distinct regression coefficients.
\item
  \(X_{1i}\), \(X_{2i}\), \ldots, \(X_{1n}\) are the values of the
  independent variables for observation \emph{i}.
\item
  \(\sigma\) is the prior distribution for the standard deviation,
  ensuring it is positive.
\end{itemize}

\section{Reference(s)}\label{references-1}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Interaction terms}\label{interaction-terms}

\section{General Principles}\label{general-principles-2}

To study relationships between two independent continuous variables and
their interaction effect on a dependent variable (e.g., temperature and
humidity affecting energy consumption), we can use Regression Analysis
with Interaction Terms. In this approach, we extend the simple linear
regression model to include an interaction term (a multiplication)
between the two continuous variables.

Parallel lines indicate that there is no interaction effect, while
different slopes suggest that one might be present. Below is the plot
for Food x Condiment. The crossed lines on the graph suggest that there
is an interaction effect, which the significant p-value for the
Food*Condiment term confirms. The graph shows that enjoyment levels are
higher for chocolate sauce when the food is ice cream. Conversely,
satisfaction levels are higher for mustard when the food is a hot dog.
If you put mustard on ice cream or chocolate sauce on hot dogs, you
won't be happy!

\includegraphics{index_files/mediabag/interactions_plot_ca.png}

\section{Considerations}\label{considerations-2}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  Model the relationship between Y and R to vary as a function of A. You
  explicitly model the hypothesis that the slope between Y and R
  depends---is conditional---upon A.
\item
  For continuous interactions, the intercept becomes the grand mean of
  the outcome variable. This ease of interpretation alone is a good
  reason to center predictor variables.
\item
  The interpretation of estimates is more difficult, as the estimate of
  non-interaction terms becomes the expected change in Y when R
  increases by one unit and A is at its average value. The estimate of
  interaction terms represents the expected change in the influence of A
  on Y when increasing R by one unit and the expected change in the
  influence of R on Y when increasing A by one unit.
\item
  \phantomsection\label{triptych}{{Triptych üõà}} plots are very handy for
  understanding the impact of interactions.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-2}

Below is an example code snippet demonstrating Bayesian regression with
an interaction term between two continuous variables with the Bayesian
Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/tulips.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.scale([}\StringTok{\textquotesingle{}blooms\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}shade\textquotesingle{}}\NormalTok{])}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}blooms\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}shade\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(blooms, shade, water):}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal(}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.25}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ dist.exponential(}\DecValTok{1}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta1 }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}beta1\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta2 }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}beta2\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta\_interaction\_ }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}beta\_interaction\_\textquotesingle{}}\NormalTok{)    }
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Normal(alpha }\OperatorTok{+}\NormalTok{ beta1 }\OperatorTok{*}\NormalTok{ water }\OperatorTok{+}\NormalTok{ beta2 }\OperatorTok{*}\NormalTok{ shade }\OperatorTok{+}\NormalTok{ beta\_interaction\_ }\OperatorTok{*}\NormalTok{ water }\OperatorTok{*}\NormalTok{ shade, sigma), obs}\OperatorTok{=}\NormalTok{blooms)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/tulips.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{scale}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}blooms\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}shade\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}blooms\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}water\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}shade\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(blooms, water,shade)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{,}\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  beta1 }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\DecValTok{0}\NormalTok{,  }\FloatTok{0.25}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b1\textquotesingle{}}\NormalTok{,}\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  beta2 }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(  }\DecValTok{0}\NormalTok{,  }\FloatTok{0.25}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}b2\textquotesingle{}}\NormalTok{,}\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))   }
\NormalTok{  beta\_interaction\_ }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(  }\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}bint\textquotesingle{}}\NormalTok{,}\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{))) }
\NormalTok{  sigma }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{uniform}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}s\textquotesingle{}}\NormalTok{,}\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Normal}\NormalTok{(alpha }\SpecialCharTok{+}\NormalTok{ beta1}\SpecialCharTok{*}\NormalTok{water }\SpecialCharTok{+}\NormalTok{ beta2}\SpecialCharTok{*}\NormalTok{shade }\SpecialCharTok{+}\NormalTok{ beta\_interaction\_}\SpecialCharTok{*}\NormalTok{water}\SpecialCharTok{*}\NormalTok{shade, sigma), }\AttributeTok{obs=}\NormalTok{blooms)}
\NormalTok{\}}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-2}

\section{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-2}

We model the relationship between the input features (X1 and X2) and the
target variable (Y) using the following equation: \[
ùëå_i = \alpha + \beta_1ùëã_{1i} + \beta_2ùëã_{2i} + \beta_{interaction}ùëã_{1i}ùëã_{2i} + \sigma
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(X_{1i}\) and \(X_{2i}\) are the two values of the independent
  continuous variables for observation \emph{i}.
\item
  \(\beta_1\) and \(\beta_2\) are the regression coefficients for
  \(X_{1i}\) and \(X_{2i}\), respectively.
\item
  \(\beta_{interaction}\) is the regression coefficient for the
  interaction term \((X_{1i}  X_{2i})\).
\item
  \(\sigma\) is the error term assumed to be normally distributed.
\end{itemize}

In this context, the interaction term \(X_{1i} * X_{2i}\) captures the
joint effect of \(X_{1i}\) and \(X_{2i}\) on the target variable
\(Y_i\).

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-2}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
Y \sim Normal(\alpha +  \beta_1  X_{1i}‚Äã + \beta_2  X_{2i}‚Äã‚Äã + \beta_{interaction}  X_1{1i} X_{2i}‚Äã ,  \sigma)
\]

\[
\alpha \sim Normal(0,1)
\]

\[
\beta_1 \sim Normal(0,1)
\]

\[
\beta_2 \sim Normal(0,1)
\]

\[
\beta_{interaction} \sim Normal(0,1)
\]

\[
œÉ \sim Exponential(1)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the prior distribution for the intercept.
\item
  \(\beta_1\), \(\beta_2\), and \(\beta_{interaction}\) are the prior
  distributions for the regression coefficients.
\item
  \(X_{1i}\) and \(X_{2i}\) are the two values of the independent
  continuous variables for observation \emph{i}.
\item
  \(\sigma\) is the prior distribution for the standard deviation,
  ensuring it is positive.
\end{itemize}

\section{Reference(s)}\label{references-2}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Regression for Categorical
Variables}\label{regression-for-categorical-variables}

\section{General Principles}\label{general-principles-3}

To study the relationship between a categorical independent variable and
a continuous dependent variable, we use a \emph{Categorical model} which
applies \emph{stratification}.

\emph{Stratification} consists of modeling how the different categories
of the independent variable affect the target continuous variable by
performing a regression for each category and assigning a regression
coefficient for each category. To realize the \emph{stratification},
categorical variables are often encoded using one-hot encoding or
converting categories to indices.

\includegraphics{index_files/mediabag/tumblr_inline_o8j406.png}

\section{Considerations}\label{considerations-3}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  As we generate regression coefficients for each \emph{k} category in
  the code, we need to specify a prior with a shape equal to the number
  of categories (see comments in the code).
\item
  To compare differences between categories, we need to compute the
  distribution of the differences between categories, known as the
  contrast distribution. \textbf{Never compare the confidence intervals
  or p-values directly.}
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-3}

Below is an example code snippet demonstrating Bayesian regression with
an independent categorical variable using the Bayesian Inference (BI)
package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/milk.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.index([}\StringTok{"clade"}\NormalTok{])}
\NormalTok{m.scale([}\StringTok{\textquotesingle{}kcal\_per\_g\textquotesingle{}}\NormalTok{])}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}kcal\_per\_g\textquotesingle{}}\NormalTok{, }\StringTok{"index\_clade"}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(kcal\_per\_g, index\_clade):    }
\NormalTok{    beta }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(}\DecValTok{4}\NormalTok{,), name}\OperatorTok{=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{)  }\CommentTok{\# we specify a vector of length 4 as we have 4 categories}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ bi.dist.exponential(}\DecValTok{1}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Normal(beta[index\_clade], sigma), obs}\OperatorTok{=}\NormalTok{kcal\_per\_g)}


\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/milk.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{scale}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}kcal\_per\_g\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{index}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}clade\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}kcal\_per\_g\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}index\_clade\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(kcal\_per\_g, index\_clade)\{}
\NormalTok{  beta }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{,}\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  sigma }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{exponential}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}s\textquotesingle{}}\NormalTok{,}\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"Y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Normal}\NormalTok{(beta[index\_clade], sigma), }\AttributeTok{obs=}\NormalTok{kcal\_per\_g)}
\NormalTok{\}}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-3}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-3}

We model the relationship between the categorical input feature (X) and
the target variable (Y) using the following equation:

\[
Y_i = \alpha + \beta_k X_i + \sigma
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta_k\) are the regression coefficients for each \emph{k}
  category.
\item
  \(X_i\) is the encoded categorical input variable for observation
  \emph{i}.
\item
  \(\sigma\) is the error term.
\end{itemize}

We can interpret \(\beta_i\) as the effect of each category on \(Y\)
relative to the baseline (usually one of the categories or the
intercept).

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-3}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
Y \sim Normal(\alpha +  \beta_k X, \sigma)
\]

\[
\alpha \sim Normal(0,1)
\]

\[
\beta_k \sim Normal(0,1)
\]

\[
\sigma \sim Exponential(1)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\alpha\) is the prior distribution for the intercept.
\item
  \(\beta_k\) are \emph{k} prior distributions for \emph{k} regression
  coefficients.
\item
  \(X_i\) is the encoded categorical input variable for observation
  \emph{i}.
\item
  \(\sigma\) is the prior distribution for the standard deviation,
  ensuring it is positive.
\end{itemize}

\section{Notes}\label{notes}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  We can apply multiple variables similarly as in
  \href{2.\%20Multiple\%20continuous\%20Variables.qmd}{Chapter 2:
  Multiple Continuous Variables}.
\item
  We can apply interaction terms similarly as in
  \href{3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{Chapter
  3: Interaction between Continuous Variables}.
\end{itemize}

\end{tcolorbox}

\section{Reference(s)}\label{references-3}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Binomial Model}\label{binomial-model}

\section{General Principles}\label{general-principles-4}

To model the relationship between a binary outcome ---e.g.,
success/failure, yes/no, or 1/0---and one or more independent variables,
we can use a Binomial model.

\includegraphics{index_files/mediabag/xHlvv.png}

\section{Considerations}\label{considerations-4}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  We have the first \phantomsection\label{linkF}{{link function üõà}}
  \emph{logit}. The \emph{logit} link function in the Bayesian binomial
  model converts the linear combination of predictor variables into
  probabilities, making it suitable for modeling binary outcomes. It
  helps estimate the relationship between predictors and the probability
  of success, ensuring results fall within the bounds of the binomial
  distribution.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-4}

Below is an example code snippet demonstrating Bayesian binomial
regression using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/chimpanzees.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}pulled\_left\textquotesingle{}}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(pulled\_left):}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Binomial(logits}\OperatorTok{=}\NormalTok{alpha[actor] }\OperatorTok{+}\NormalTok{ beta1[side] }\OperatorTok{+}\NormalTok{ beta2[cond]), obs}\OperatorTok{=}\NormalTok{pulled\_left)}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model, init\_strategy}\OperatorTok{=}\NormalTok{numpyro.infer.initialization.init\_to\_mean()) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/chimpanzees.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}pulled\_left\textquotesingle{}}\NormalTok{))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pulled\_left)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{( }\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"Y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Binomial}\NormalTok{(}\AttributeTok{logits =}\NormalTok{ alpha), }\AttributeTok{obs=}\NormalTok{pulled\_left)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-4}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-4}

We model the relationship between the independent variable (\(X_i\)) and
the binary dependent variable (\(Y_i\)) using the following equation: \[
logit(Y_i) = \alpha + \beta X 
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the probability of success (or the probability of the
  binary outcome being 1) for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression coefficient.
\item
  \(X_i\) is the value of the independent variable for observation
  \emph{i}.
\item
  \(logit(Y_i)\) is the log-odds of success, calculated as the log of
  the odds ratio of success. Through this link function, the
  relationship between the independent variables and the log-odds of
  success is modeled linearly, allowing us to interpret the effect of
  each independent variable on the log-odds of success for observation
  \emph{i}.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-4}

\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[ 
Y \sim Binomial(n = 1, p)
\]

\[
logit(p) \sim \alpha + \beta X_i
\]

\[
\alpha \sim Normal(0,1)
\]

\[
\beta \sim Normal(0,1)
\]

Where:

\begin{itemize}
\item
  \(Y\) is the likelihood function.
\item
  \(\beta\) and \(p(\alpha)\) are the prior distributions for the
  regression coefficients and intercept, respectively.
\item
  \(n = 1\) represents the number of trials in the binomial distribution
  (binary outcome).
\item
  \(logit(\alpha + \beta X)\) is the \emph{logit} link function that is
  equal to the sigmoid function applied to the linear combination of
  predictors, mapping the log-odds to probabilities.
\end{itemize}

\section{Notes}\label{notes-1}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  We can apply multiple variables similarly as in
  \href{./2.\%20Multiple\%20Regression\%20for\%20Continuous\%20Variables.qmd}{chapter
  2}.
\item
  We can apply interaction terms similarly as in
  \href{/3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{chapter
  3}.
\item
  We can apply categorical variables similarly as in
  \href{4.\%20Categorical\%20variable.qmd}{chapter 4}.
\item
  Below is an example code snippet demonstrating a Bayesian binomial
  model for multiple categorical variables:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/chimpanzees.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.df[}\StringTok{"side"}\NormalTok{] }\OperatorTok{=}\NormalTok{ m.df.prosoc\_left  }\CommentTok{\# right 0, left 1}
\NormalTok{m.df[}\StringTok{"cond"}\NormalTok{] }\OperatorTok{=}\NormalTok{ m.df.condition  }\CommentTok{\# no partner 0, partner 1}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}pulled\_left\textquotesingle{}}\NormalTok{, }\StringTok{"actor"}\NormalTok{, }\StringTok{"side"}\NormalTok{, }\StringTok{"cond"}\NormalTok{])}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(pulled\_left):}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(}\DecValTok{7}\NormalTok{,), name}\OperatorTok{=}\StringTok{"alpha"}\NormalTok{)  }\CommentTok{\# generating k intercepts (one for each actor)}
\NormalTok{    beta1 }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(}\DecValTok{2}\NormalTok{,), name}\OperatorTok{=}\StringTok{"beta"}\NormalTok{)  }\CommentTok{\# generating k regression coefficients for each k prosoc\_left}
\NormalTok{    beta2 }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{10}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(}\DecValTok{2}\NormalTok{,), name}\OperatorTok{=}\StringTok{"beta"}\NormalTok{)  }\CommentTok{\# generating k regression coefficients for each k condition}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Binomial(logits}\OperatorTok{=}\NormalTok{alpha[actor] }\OperatorTok{+}\NormalTok{ beta1[side] }\OperatorTok{+}\NormalTok{ beta2[cond]), obs}\OperatorTok{=}\NormalTok{pulled\_left)}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model, init\_strategy}\OperatorTok{=}\NormalTok{numpyro.infer.initialization.init\_to\_mean()) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\section{Reference(s)}\label{references-4}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Beta-Binomial Model}\label{beta-binomial-model}

\section{General Principles}\label{general-principles-5}

To model the relationship between a binary outcome variable representing
success counts and one or more independent variables with
\phantomsection\label{overdispersion}{{overdispersion üõà}}, we can use
the Beta-Binomial model.

We model the relationship between the predictor variables (X1, X2,
\ldots, Xn) and the probability of success (p) using the following
equation:

\section{Considerations}\label{considerations-5}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{5.\%20Binomial\%20model.qmd}{Binomial regression}.
\item
  A Beta-Binomial model assumes that each binomial count observation has
  its own probability of success. The model estimates the distribution
  of probabilities of success across cases, instead of a single
  probability of success.
\item
  A Beta distribution has two parameters: an average probability
  \emph{p} and a shape parameter Œ∏.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-5}

Below is an example code snippet demonstrating Bayesian Beta-Binomial
regression using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}\CommentTok{\#}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi()}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/UCBadmit.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.df[}\StringTok{"gid"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (m.df[}\StringTok{"applicant.gender"}\NormalTok{] }\OperatorTok{!=} \StringTok{"male"}\NormalTok{).astype(}\BuiltInTok{int}\NormalTok{)}
\NormalTok{gid }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"gid"}\NormalTok{].astype(}\StringTok{\textquotesingle{}int32\textquotesingle{}}\NormalTok{).values)}
\NormalTok{applications }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"applications"}\NormalTok{].astype(}\StringTok{\textquotesingle{}float32\textquotesingle{}}\NormalTok{).values)}
\NormalTok{admit }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"admit"}\NormalTok{].astype(}\StringTok{\textquotesingle{}float32\textquotesingle{}}\NormalTok{).values)}

\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    gid}\OperatorTok{=}\NormalTok{gid,}
\NormalTok{    applications}\OperatorTok{=}\NormalTok{applications,}
\NormalTok{    admit}\OperatorTok{=}\NormalTok{admit}
\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(gid, applications, admit):}
\NormalTok{    phi }\OperatorTok{=}\NormalTok{ dist.exponential(}\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{1}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}phi\textquotesingle{}}\NormalTok{)}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal(}\FloatTok{0.}\NormalTok{, }\FloatTok{1.5}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{2}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{    theta }\OperatorTok{=}\NormalTok{ phi }\OperatorTok{+} \DecValTok{2}
\NormalTok{    pbar }\OperatorTok{=}\NormalTok{ jax.nn.sigmoid(alpha[gid])}
\NormalTok{    concentration1 }\OperatorTok{=}\NormalTok{ pbar }\OperatorTok{*}\NormalTok{ theta}
\NormalTok{    concentration0 }\OperatorTok{=}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ pbar) }\OperatorTok{*}\NormalTok{ theta}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, BetaBinomial(total\_count}\OperatorTok{=}\NormalTok{applications, concentration1}\OperatorTok{=}\NormalTok{concentration1, concentration0}\OperatorTok{=}\NormalTok{concentration0), obs}\OperatorTok{=}\NormalTok{admit)}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/UCBadmit.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\NormalTok{df[}\StringTok{"gid"}\NormalTok{] }\OtherTok{=} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{df[}\StringTok{"applicant.gender"}\NormalTok{] }\SpecialCharTok{==} \StringTok{"male"}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}gid\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}applications\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}admit\textquotesingle{}}\NormalTok{ ))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(gid, applications, admit)\{}
\NormalTok{  phi }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{exponential}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{name =} \StringTok{\textquotesingle{}phi\textquotesingle{}}\NormalTok{)}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\FloatTok{0.}\NormalTok{, }\FloatTok{1.5}\NormalTok{, }\AttributeTok{shape=} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{2}\NormalTok{)), }\AttributeTok{name=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{  theta }\OtherTok{=}\NormalTok{ phi }\SpecialCharTok{+} \DecValTok{2}
\NormalTok{  pbar }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{jax}\SpecialCharTok{$}\NormalTok{nn}\SpecialCharTok{$}\FunctionTok{sigmoid}\NormalTok{(alpha[gid])}
\NormalTok{  concentration1 }\OtherTok{=}\NormalTok{ pbar }\SpecialCharTok{*}\NormalTok{ theta}
\NormalTok{  concentration0 }\OtherTok{=}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pbar) }\SpecialCharTok{*}\NormalTok{ theta}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{BetaBinomial}\NormalTok{(}\AttributeTok{total\_count=}\NormalTok{applications, }\AttributeTok{concentration1=}\NormalTok{concentration1, }\AttributeTok{concentration0=}\NormalTok{concentration0), }\AttributeTok{obs=}\NormalTok{admit)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-5}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula}

\[
logit(p_i) = \alpha + \beta X_i
\]

Where:

\begin{itemize}
\item
  \(p_i\) is the probability of success for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression term.
\item
  \(X_i\) is the value of the independent variable for observation
  \emph{i}.
\item
  \(\text{logit}(p_i)\) is the log-odds of success for observation
  \emph{i}.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
Model}}{Bayesian Model}}\label{bayesian-model}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
Y_i \sim BetaBinomial(n_i, p_i, \theta)
\]

\[
logit(p_i) \sim \alpha + \beta X
\]

\[
\alpha \sim Normal(0,1)
\]

\[
\theta \sim HalfCauchy(0,1)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the dependent variable for observation \emph{i}.
\item
  \(n_i\) is the total count of trials for observation \emph{i}.
\item
  \(p_i\) is the probability of success for observation \emph{i}.
\item
  \(\theta\) is the shape distribution term.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression coefficient term.
\item
  \(X_i\) is the value of the independent variable for observation
  \emph{i}.
\end{itemize}

\section{Reference(s)}\label{references-5}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Poisson model}\label{poisson-model}

\section{General Principles}\label{general-principles-6}

To model the relationship between a count outcome variable---e.g.,
counts of events occurring in a fixed interval of time or space---and
one or more independent variables, we can use the Poisson model.

This is a special shape of the binomial distribution; it is useful
because it models binomial events for which the number of trials ( n )
is unknown or uncountably large.

\includegraphics{index_files/mediabag/Comparison-of-linear.png}

\section{Considerations}\label{considerations-6}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  We have the second \phantomsection\label{linkF}{{link function üõà}}.
  The conventional link function for a Poisson model is the \emph{log}
  link (it ensures that \emph{Œª} is always positive).
\item
  To invert the log link function and model linearly the relationship
  between the predictor variables and the log of the mean rate
  parameter, we can apply the exponential function (see comment in
  code).
\end{itemize}

\[
log(\lambda_i) = log(\tau_i) + \alpha + \beta x_i
\]

\begin{itemize}
\tightlist
\item
  The offset \(œÑ_i\) scales the expected number of events for each case
  \(i\).
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-6}

Below is an example code snippet demonstrating a Bayesian Poisson model
using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi()}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/Kline.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.sale([}\StringTok{"population"}\NormalTok{]) }
\NormalTok{m.df[}\StringTok{"cid"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (m.df.contact }\OperatorTok{==} \StringTok{"high"}\NormalTok{).astype(}\BuiltInTok{int}\NormalTok{)}

\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}total\_tools\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}population\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}cid\textquotesingle{}}\NormalTok{])}


\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(cid, P, total\_tools):}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{3}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{    beta }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.2}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{)}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Poisson(jnp.exp(alpha[cid] }\OperatorTok{+}\NormalTok{ beta[cid]}\OperatorTok{*}\NormalTok{P)), obs}\OperatorTok{=}\NormalTok{total\_tools)  }\CommentTok{\# Exponential ensures non{-}negative values and inverts the log link function}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/Kline.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{scale}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}population\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{df[}\StringTok{"cid"}\NormalTok{] }\OtherTok{=}  \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{ifelse}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{contact }\SpecialCharTok{==} \StringTok{"high"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}total\_tools\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}population\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}cid\textquotesingle{}}\NormalTok{ ))}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{data\_on\_model}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(total\_tools, population, cid)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{3}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  beta }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  l }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{jnp}\SpecialCharTok{$}\FunctionTok{exp}\NormalTok{(alpha[cid] }\SpecialCharTok{+}\NormalTok{ beta[cid]}\SpecialCharTok{*}\NormalTok{population)}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Poisson}\NormalTok{(l), }\AttributeTok{obs=}\NormalTok{total\_tools)}
\NormalTok{\}}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-6}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-5}

We model the relationship between the predictor variable (\(X_i\)) and
the count outcome variable (\(Y_i\)) using the following equation:

\[
\log(\lambda_i) = \alpha + \beta  X_i 
\]

Where:

\begin{itemize}
\item
  \(\lambda_i\) is the mean rate parameter of the Poisson distribution
  (expected count) for observation \emph{i}, modeled as the exponential
  function of the linear combination of predictors.
\item
  \(\log(\lambda_i)\) is the log of the mean rate parameter for
  observation \emph{i}, ensuring it is positive.
\item
  \(\beta\) are the regression coefficients.
\item
  \(\alpha\) is the intercept term.
\item
  \(X_i\) is the value for the independent variables for observation
  \emph{i}.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-5}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
Y \sim Poisson(\lambda_i)
\]

\[
\log(\lambda_i) \sim \alpha + \beta X_i
\]

\[
\alpha \sim Normal(0, 1)
\]

\[
\beta \sim Normal(0, 1)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is the dependent variable for observation \emph{i}.
\item
  \(\lambda_i\) is the mean rate parameter of the Poisson distribution
  for observation \emph{i}, modeled as the exponential function of the
  linear combination of predictors.
\item
  \(\log(\lambda_i)\) is the log of the mean rate parameter for
  observation \emph{i}.
\item
  \(\alpha\) and \(\beta\) are the prior distributions for the intercept
  and the regression coefficients, respectivelly .
\item
  \(\lambda\) is the mean rate parameter of the Poisson distribution,
  modeled as the exponential function of the linear combination of
  predictors.
\item
  \(X_i\) is the value for the independent variables for observation
  \emph{i}.
\end{itemize}

\section{Notes}\label{notes-2}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  We can apply multiple variables similarly as in
  \href{2.\%20Multiple\%20Regression\%20for\%20Continuous\%20Variables.qmd}{chapter
  2}.
\item
  We can apply interaction terms similarly as in
  \href{3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{chapter
  3}.
\item
  We can apply categorical variables similarly as in
  \href{4.\%20Categorical\%20variable.md}{chapter 4}.
\end{itemize}

\end{tcolorbox}

\section{Reference(s)}\label{references-6}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Gamma-Poisson model}\label{gamma-poisson-model}

\section{General Principles}\label{general-principles-7}

To model the relationship between a count outcome variable and one or
more independent variables with
\phantomsection\label{overdispersion}{{overdispersion üõà}}, we can use
the \emph{Negative Binomial model}.

\section{Considerations}\label{considerations-7}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for the
  \href{7.\%20Poisson\%20model.qmd}{Poisson model}.
\item
  Overdispersion is handled because the Negative Binomial model assumes
  that each Poisson count observation has its own rate. This is an
  additional parameter specified in the model (in the code, it is
  \texttt{log\_days}).
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-7}

Below is an example code snippet demonstrating Bayesian Gamma-Poisson
model using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulate data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\ImportTok{import}\NormalTok{ tensorflow\_probability.substrates.jax.distributions }\ImportTok{as}\NormalTok{ tfd}
\NormalTok{init\_key, sample\_key }\OperatorTok{=}\NormalTok{ random.split(random.PRNGKey(}\BuiltInTok{int}\NormalTok{(r.randint(}\DecValTok{0}\NormalTok{, }\DecValTok{10000000}\NormalTok{))))}
\NormalTok{init\_key }\OperatorTok{=}\NormalTok{ jnp.array(init\_key)}
\NormalTok{num\_days }\OperatorTok{=} \DecValTok{30}
\NormalTok{y }\OperatorTok{=}\NormalTok{ tfd.Poisson(rate}\OperatorTok{=}\FloatTok{1.5}\NormalTok{).sample(seed}\OperatorTok{=}\NormalTok{init\_key, sample\_shape}\OperatorTok{=}\NormalTok{(num\_days,))}
\NormalTok{num\_weeks }\OperatorTok{=} \DecValTok{4}
\NormalTok{y\_new }\OperatorTok{=}\NormalTok{ tfd.Poisson(rate}\OperatorTok{=}\FloatTok{0.5} \OperatorTok{*} \DecValTok{7}\NormalTok{).sample(seed}\OperatorTok{=}\NormalTok{init\_key, sample\_shape}\OperatorTok{=}\NormalTok{(num\_weeks,))}
\NormalTok{y\_all }\OperatorTok{=}\NormalTok{ np.concatenate([y, y\_new])}
\NormalTok{exposure }\OperatorTok{=}\NormalTok{ np.concatenate([np.repeat(}\DecValTok{1}\NormalTok{, }\DecValTok{30}\NormalTok{), np.repeat(}\DecValTok{7}\NormalTok{, }\DecValTok{4}\NormalTok{)])}
\NormalTok{monastery }\OperatorTok{=}\NormalTok{ np.concatenate([np.repeat(}\DecValTok{0}\NormalTok{, }\DecValTok{30}\NormalTok{), np.repeat(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{)])}
\NormalTok{d }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_dict(}\BuiltInTok{dict}\NormalTok{(y}\OperatorTok{=}\NormalTok{y\_all, days}\OperatorTok{=}\NormalTok{exposure, monastery}\OperatorTok{=}\NormalTok{monastery))}
\NormalTok{d[}\StringTok{"log\_days"}\NormalTok{] }\OperatorTok{=}\NormalTok{ d.days.pipe(np.log)}
\NormalTok{d.to\_csv(}\StringTok{\textquotesingle{}Sim dat Gamma poisson.csv\textquotesingle{}}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\ImportTok{from}\NormalTok{ main }\ImportTok{import} \OperatorTok{*}
\CommentTok{\# Setup device {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi()}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    log\_days}\OperatorTok{=}\NormalTok{jnp.array(d.log\_days.values),  }\CommentTok{\# rate of each count data}
\NormalTok{    monastery}\OperatorTok{=}\NormalTok{jnp.array(d.monastery.values),}
\NormalTok{    output}\OperatorTok{=}\NormalTok{jnp.array(d.y.values)}
\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(log\_days, monastery, output):}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{1}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{)}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{1}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{)}
\NormalTok{    l }\OperatorTok{=}\NormalTok{ log\_days }\OperatorTok{+}\NormalTok{ a }\OperatorTok{+}\NormalTok{ b }\OperatorTok{*}\NormalTok{ monastery}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Poisson(rate}\OperatorTok{=}\NormalTok{l), obs}\OperatorTok{=}\NormalTok{output)}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}Sim dat Gamma poisson.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}log\_days\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}monastery\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}y\textquotesingle{}}\NormalTok{ ))}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(log\_days, monastery, y)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{  beta }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{)}
\NormalTok{  l }\OtherTok{=}\NormalTok{ log\_days }\SpecialCharTok{+}\NormalTok{ alpha }\SpecialCharTok{+}\NormalTok{ beta }\SpecialCharTok{*}\NormalTok{ monastery}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Poisson}\NormalTok{(}\AttributeTok{rate=}\NormalTok{l), }\AttributeTok{obs=}\NormalTok{y)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }
\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-7}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula-1}

We model the relationship between the independent variable \(X\) and the
count outcome variable \(Y\) using the following equation:

\[
\log(\lambda_i) = \exp(\text{rates}_i + \alpha + \beta X_i)
\]

Where:

\begin{itemize}
\item
  \(\lambda_i\) is the mean rate parameter of the negative binomial
  distribution (expected count) for observation \emph{i}.
\item
  \(\log(\lambda_i)\) is the log of the mean rate parameter, ensuring it
  is positive for observation \emph{i}.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression coefficients.
\item
  \(X_i\) is the value of the predictor variable for observation
  \emph{i}.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
model}}{Bayesian model}}\label{bayesian-model-1}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
Y_i \sim \text{Poisson}(\lambda)
\]

\[
\log(\lambda_i) \sim \text{rates}_i + \alpha + \beta X_i
\]

\[
\alpha \sim \text{Normal}(0,1)
\]

\[
\beta \sim \text{Normal}(0,1)
\]

Where:

\begin{itemize}
\item
  \(Y_i\) is dependent variable for observation \emph{i}.
\item
  \(\lambda_i\) is the mean rate parameter of the Poisson distribution
  for observation \emph{i}, assuming that each Poisson count observation
  has its own \(rate_i\).
\item
  \(\log(\lambda_i)\) is the log of the mean rate parameterfor
  observation \emph{i}, ensuring it is positive.
\item
  \(\alpha\) is the intercept term.
\item
  \(\beta\) is the regression coefficients.
\item
  \(X_i\) is the value of the predictor variable for observation
  \emph{i}.
\end{itemize}

\section{Notes}\label{notes-3}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  We can apply multiple variables similarly as in
  \href{2.\%20Multiple\%20Regression\%20for\%20Continuous\%20Variables.qmd}{chapter
  2}.
\item
  We can apply interaction terms similarly as in
  \href{3.\%20Interaction\%20between\%20Continuous\%20Variables.qmd}{chapter
  3}.
\item
  We can apply categorical variables similarly as in
  \href{4.\%20Categorical\%20variable.md}{chapter 4}.
\end{itemize}

\end{tcolorbox}

\section{Reference(s)}\label{references-7}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Multinomial model}\label{multinomial-model}

\section{General Principles}\label{general-principles-8}

To model the relationship between a categorical outcome variable with
more than two categories and one or more independent variables, we can
use a \emph{Multinomial} distribution.

\includegraphics{index_files/mediabag/Multinomial-Logistic.jpg}

\section{Considerations}\label{considerations-8}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  One way to interpret a multinomial model is to consider that we need
  to build \(K - 1\) linear models, where \(K\) is the number of
  categories. Once we get the linear prediction for each category, we
  can convert these predictions to probabilities by building a
  \phantomsection\label{simplex}{{simplex üõà}}. To do this, we convert
  the regression outputs using the softmax function (see the
  ``nn.softmax'' line in the code).
\item
  The intercept captures the difference in the log-odds of the outcome
  categories; thus, different categories need different intercepts.
\item
  On the other hand, as we assume that the effect of each predictor on
  the outcome is consistent across all categories, the regression
  coefficients are shared across categories.
\item
  The relationship between the predictor variables and the log-odds of
  each category is modeled linearly, allowing us to interpret the effect
  of each predictor on the log-odds of each category.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-8}

Below is an example code snippet demonstrating Bayesian multinomial
model using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}
\CommentTok{\# Simulated data{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\# simulate career choices among 500 individuals}
\NormalTok{N }\OperatorTok{=} \DecValTok{500}  \CommentTok{\# number of individuals}
\NormalTok{income }\OperatorTok{=}\NormalTok{ jnp.array([}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{])  }\CommentTok{\# expected income of each career}
\NormalTok{score }\OperatorTok{=} \FloatTok{0.5} \OperatorTok{*}\NormalTok{ income  }\CommentTok{\# scores for each career, based on income}

\CommentTok{\# next line converts scores to probabilities}
\NormalTok{p }\OperatorTok{=}\NormalTok{ jnp.array(jax.nn.softmax(score))}

\CommentTok{\# now simulate choice}
\CommentTok{\# outcome career holds event type values, not counts}
\NormalTok{career }\OperatorTok{=}\NormalTok{ bi.dist.categorical(p, shape}\OperatorTok{=}\NormalTok{N, sample}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    income}\OperatorTok{=}\NormalTok{income,}
\NormalTok{    career}\OperatorTok{=}\NormalTok{career}
\NormalTok{)}
\NormalTok{d.to\_csv(}\StringTok{\textquotesingle{}Sim data multinomial.csv\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(income, career):}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{2}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{)}
\NormalTok{    b }\OperatorTok{=}\NormalTok{ dist.halfnormal(}\FloatTok{0.5}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{1}\NormalTok{], name}\OperatorTok{=}\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{)}
\NormalTok{    s\_1 }\OperatorTok{=}\NormalTok{ a[}\DecValTok{0}\NormalTok{] }\OperatorTok{+}\NormalTok{ b }\OperatorTok{*}\NormalTok{ income[}\DecValTok{0}\NormalTok{]}
\NormalTok{    s\_2 }\OperatorTok{=}\NormalTok{ a[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ b }\OperatorTok{*}\NormalTok{ income[}\DecValTok{1}\NormalTok{]}
\NormalTok{    s\_3 }\OperatorTok{=}\NormalTok{ a[}\DecValTok{0}\NormalTok{] }\OperatorTok{+}\NormalTok{ b }\OperatorTok{*}\NormalTok{ income[}\DecValTok{0}\NormalTok{]}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ jax.nn.softmax(jnp.stack([s\_1[}\DecValTok{0}\NormalTok{], s\_2[}\DecValTok{0}\NormalTok{], s\_3[}\DecValTok{0}\NormalTok{]]))}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Categorical(probs}\OperatorTok{=}\NormalTok{p[career]), obs}\OperatorTok{=}\NormalTok{career)}

\CommentTok{\# Run sampler {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} }
\NormalTok{m.run(model)  }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}Sim data multinomial.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }

\NormalTok{keys }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"income"}\NormalTok{, }\StringTok{"career"}\NormalTok{)}
\NormalTok{income }\OtherTok{=} \FunctionTok{unique}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{income)}
\NormalTok{income }\OtherTok{=}\NormalTok{ income[}\FunctionTok{order}\NormalTok{(income)]}
\NormalTok{values }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(income), }\FunctionTok{as.integer}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{career))}
\NormalTok{m.data\_on\_model }\OtherTok{=} \FunctionTok{py\_dict}\NormalTok{(keys, values, }\AttributeTok{convert =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{m.data\_on\_model}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(income, career)\{}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{2}\NormalTok{)))}
\NormalTok{  beta }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{halfnormal}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}beta\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{)))}
\NormalTok{  s\_1 }\OtherTok{=}\NormalTok{ alpha[}\DecValTok{0}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ beta }\SpecialCharTok{*}\NormalTok{ income[}\DecValTok{1}\NormalTok{]}
\NormalTok{  s\_2 }\OtherTok{=}\NormalTok{ alpha[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ beta }\SpecialCharTok{*}\NormalTok{ income[}\DecValTok{1}\NormalTok{]}
\NormalTok{  s\_3 }\OtherTok{=}\NormalTok{ alpha[}\DecValTok{0}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ beta }\SpecialCharTok{*}\NormalTok{ income[}\DecValTok{0}\NormalTok{]}
\NormalTok{  p }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{jax}\SpecialCharTok{$}\NormalTok{nn}\SpecialCharTok{$}\FunctionTok{softmax}\NormalTok{(bi}\SpecialCharTok{$}\NormalTok{jnp}\SpecialCharTok{$}\FunctionTok{stack}\NormalTok{(}\FunctionTok{list}\NormalTok{(s\_1[}\DecValTok{0}\NormalTok{], s\_2[}\DecValTok{0}\NormalTok{], s\_3[}\DecValTok{0}\NormalTok{])))}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Categorical}\NormalTok{(}\AttributeTok{probs=}\NormalTok{p[career]), }\AttributeTok{obs=}\NormalTok{career)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-8}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula-2}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We model the relationship
between the predictor variables (X1, X2, \ldots, Xn) and the categorical
outcome variable (\(Y_i\)) using the following equation:

\[
logit(p_ik) = log(\frac{p_ik}{p_iK})  = Œ≤_k^T X_i + Œ±_k
\]

Where:

\begin{itemize}
\item
  \(p_ik\) is the probability of the ùëñ-th observation being in category
  ùëò.
\item
  \(Œ≤_k\) is the regression coefficients for category ùëò.
\item
  \(Œ±_k\) is the intercept for category ùëò.
\item
  \(X_i\) is the vector of predictor variables for the ùëñ-th observation.
\item
  The reference category ùêæ is often chosen to simplify the model (Note
  that we did not do this in the code).
\end{itemize}

We can express the Bayesian Multinomial model as follows:

If \(K‚ààN ,  N‚ààN , and  Œ∏‚ààK\)-simplex , then for \(y‚ààNK\) such that
\(‚àëKk=1yk=N\):

\subsection{\texorpdfstring{\emph{Bayesian
model}}{Bayesian model}}\label{bayesian-model-2}

In Bayesian multinomial modeling, the likelihood function of the data is
specified using a multinomial distribution. The multinomial distribution
models the counts of outcomes falling into different categories. For an
outcome variable ùë¶ with ùêæ categories, the multinomial likelihood
function is: \[
Multinomial(y|Œ∏)=\frac{N!}{‚àè^K_{k=1}yk!} ‚àè_{k=1}^{K} Œ∏_{k}^{y_k}
\]

Where:

\begin{itemize}
\item
  \(y=(y_1, y_2,‚Ä¶,y_K)\) represents the counts of observations in each
  of the ùêæ categories.
\item
  \(N\) is the total number of observations or trials.
\item
  \(Œ∏=(Œ∏_1,Œ∏_2,‚Ä¶,Œ∏_K)\) is a simplex of category probabilities, with
  \(Œ∏_k\) representing the probability of category ùëò.
\item
  \(\frac{N!}{‚àè^K_{k=1}yk!}\) is the multinomial coefficient that
  accounts for the number of ways to arrange the observations into the
  categories. This coefficient ensures that the likelihood function
  properly accounts for the permutations of the counts across different
  categories.
\item ~
  \section{Reference(s)}\label{references-8}

  McElreath (2018)
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Dirichlet Model}\label{dirichlet-model}

\section{General Principles}\label{general-principles-9}

To model the relationship between a categorical outcome variable with
more than two categories and one or more independent variables with
\phantomsection\label{overdispersion}{{overdispersion üõà}}, we can use a
\emph{Dirichlet} distribution.

\includegraphics{index_files/mediabag/Multinomial-Logistic.jpg}

\section{Considerations}\label{considerations-9}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for the
  \href{7.\%20Multinomial\%20model.qmd}{Multinomial model}.
\item
  One major difference from the multinomial model is that the Dirichlet
  model doesn't require a simplex.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-9}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Simulated data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\ImportTok{import}\NormalTok{ seaborn }\ImportTok{as}\NormalTok{ sns}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ jax }\ImportTok{import}\NormalTok{ random}
\ImportTok{from}\NormalTok{ jax.nn }\ImportTok{import}\NormalTok{ softmax}
\ImportTok{import}\NormalTok{ jax.numpy }\ImportTok{as}\NormalTok{ jnp}
\ImportTok{import}\NormalTok{ numpyro }\ImportTok{as}\NormalTok{ numpyro}
\ImportTok{import}\NormalTok{ numpyro.distributions }\ImportTok{as}\NormalTok{ dist}
\ImportTok{from}\NormalTok{ numpyro.infer }\ImportTok{import}\NormalTok{ MCMC, NUTS, Predictive}

\CommentTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#\#\#\#\#\#\#\#\#\#\#\# SIMULATING MULTINOMIAL DATA WITH SOFTMAX LINK FUNCTION \#\#\#\#\#\#\#\#\#\#\#}
\KeywordTok{def}\NormalTok{ mysoftmax(x):}
\NormalTok{    exp\_x }\OperatorTok{=}\NormalTok{ np.exp(x }\OperatorTok{{-}}\NormalTok{ np.}\BuiltInTok{max}\NormalTok{(x))}
    \ControlFlowTok{return}\NormalTok{ exp\_x }\OperatorTok{/}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(exp\_x, axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}

\NormalTok{K }\OperatorTok{=} \DecValTok{3}
\NormalTok{N }\OperatorTok{=} \DecValTok{100}
\NormalTok{N\_obs }\OperatorTok{=} \DecValTok{2}
\NormalTok{sigma\_random }\OperatorTok{=} \FloatTok{0.6}

\CommentTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\# Fixed Effect Sim \#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\# a = np.random.normal(0, 1, K)}
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{])  }\CommentTok{\# Forcing a values}

\CommentTok{\# Factors{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{NY }\OperatorTok{=} \DecValTok{4}
\NormalTok{NV }\OperatorTok{=} \DecValTok{8}

\NormalTok{Y2 }\OperatorTok{=}\NormalTok{ np.full((NV, NY), np.nan) }
\NormalTok{means }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, NY)}
\NormalTok{offsets }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, NV)}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(NV):}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(NY):}
\NormalTok{        Y2[i, k] }\OperatorTok{=}\NormalTok{ means[k] }\OperatorTok{+}\NormalTok{ offsets[i]}

\NormalTok{b\_individual }\OperatorTok{=}\NormalTok{ np.random.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, (N, K))}
\NormalTok{mu }\OperatorTok{=}\NormalTok{ b\_individual }\OperatorTok{+}\NormalTok{ a}

\CommentTok{\# Declare an empty matrix to fill with data}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ np.empty((N }\OperatorTok{*}\NormalTok{ N\_obs, K))}

\CommentTok{\# Declare an empty vector to fill with IDs}
\BuiltInTok{id} \OperatorTok{=}\NormalTok{ []}

\CommentTok{\# Loop over each individual}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(N):}
    \CommentTok{\# Simulate N\_obs draws from the multinomial}
\NormalTok{    Y[i}\OperatorTok{*}\NormalTok{N\_obs:(i}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{N\_obs, :] }\OperatorTok{=}\NormalTok{ np.apply\_along\_axis(}\KeywordTok{lambda}\NormalTok{ x: np.random.multinomial(}\DecValTok{100}\NormalTok{, softmax(x)), }\DecValTok{0}\NormalTok{, mu[i])}
    \CommentTok{\# Assign ID vector}
    \BuiltInTok{id} \OperatorTok{+=}\NormalTok{ [i] }\OperatorTok{*}\NormalTok{ N\_obs}

\NormalTok{N }\OperatorTok{=}\NormalTok{ N }\OperatorTok{*}\NormalTok{ N\_obs}
\NormalTok{K }\OperatorTok{=}\NormalTok{ K}
\NormalTok{ni }\OperatorTok{=}\NormalTok{ N}
\NormalTok{y }\OperatorTok{=}\NormalTok{ jnp.array(Y, dtype}\OperatorTok{=}\NormalTok{jnp.int32).reshape(N, K)}
\NormalTok{i\_ID }\OperatorTok{=}\NormalTok{ jnp.array(}\BuiltInTok{id}\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\ImportTok{from}\NormalTok{ main }\ImportTok{import} \OperatorTok{*}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi()}
\KeywordTok{def}\NormalTok{ model(K, ni, y, i\_ID):}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ normal(}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, [K], }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{    Sigma\_individual }\OperatorTok{=}\NormalTok{ exponential(}\StringTok{\textquotesingle{}Sigma\_individual\textquotesingle{}}\NormalTok{, [ni], }\DecValTok{1}\NormalTok{)}
\NormalTok{    L\_individual }\OperatorTok{=}\NormalTok{ lkjcholesky(}\StringTok{\textquotesingle{}L\_individual\textquotesingle{}}\NormalTok{, [], ni, }\DecValTok{1}\NormalTok{)  }\CommentTok{\# Implies a uniform distribution over correlation matrices}
\NormalTok{    z\_individual }\OperatorTok{=}\NormalTok{ normal(}\StringTok{\textquotesingle{}z\_individual\textquotesingle{}}\NormalTok{, [ni, K], }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ random\_centered(Sigma\_individual, L\_individual, z\_individual)}
\NormalTok{    lk }\OperatorTok{=}\NormalTok{ jnp.exp(a }\OperatorTok{+}\NormalTok{ alpha[i\_ID])}
\NormalTok{    sample(}\StringTok{"y"}\NormalTok{, DirichletMultinomial(lk, }\BuiltInTok{int}\NormalTok{(}\DecValTok{100}\NormalTok{)), obs}\OperatorTok{=}\NormalTok{y)}

\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    K}\OperatorTok{=}\NormalTok{K,}
\NormalTok{    ni}\OperatorTok{=}\NormalTok{ni,}
\NormalTok{    y}\OperatorTok{=}\NormalTok{y,}
\NormalTok{    i\_ID}\OperatorTok{=}\NormalTok{i\_ID}
\NormalTok{)}

\CommentTok{\# Run sampler {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} }
\NormalTok{m.run(model)  }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-9}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula-3}

\subsection{\texorpdfstring{\emph{Bayesian
Model}}{Bayesian Model}}\label{bayesian-model-3}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\section{Reference(s)}\label{references-9}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Zero inflated}\label{zero-inflated}

\section{General Principles}\label{general-principles-10}

Zero-Inflated Regression models are used when the outcome variable is a
count variable with an excess of zero counts. These models combine a
count model (e.g., Poisson or Negative Binomial) with a separate model
for predicting the probability of excess zeros.

\section{Considerations}\label{considerations-10}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

In Bayesian Zero-Inflated regression, we consider uncertainty in the
model parameters and provide a full posterior distribution over them. We
need to declare prior distributions for
\(W_{1\pi}, W_{2\pi}, ..., W_{n\pi}\),
\(W_{1\lambda}, W_{2\lambda}, ..., W_{n\lambda}\), \(b_\pi\), and
\(b_\lambda\).

\end{tcolorbox}

\section{Example}\label{example-10}

Below is an example code snippet demonstrating Bayesian Zero-Inflated
Poisson regression using the Bayesian Inference (BI) package:

\subsection{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ jax.scipy.special }\ImportTok{import}\NormalTok{ expit}
\NormalTok{r.seed(}\DecValTok{42}\NormalTok{)}
\ImportTok{from}\NormalTok{ main }\ImportTok{import} \OperatorTok{*}

\CommentTok{\# Simulated data{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{prob\_drink }\OperatorTok{=} \FloatTok{0.2}  \CommentTok{\# 20\% of days}
\NormalTok{rate\_work }\OperatorTok{=} \DecValTok{1}     \CommentTok{\# average 1 manuscript per day}

\CommentTok{\# Sample one year of production}
\NormalTok{N }\OperatorTok{=} \DecValTok{365}

\NormalTok{np.random.seed(}\DecValTok{365}\NormalTok{)}
\NormalTok{drink }\OperatorTok{=}\NormalTok{ np.random.binomial(}\DecValTok{1}\NormalTok{, prob\_drink, N)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ drink) }\OperatorTok{*}\NormalTok{ np.random.poisson(rate\_work, N)}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}
\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    y}\OperatorTok{=}\NormalTok{jnp.array(y)}
\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(y):}
\NormalTok{    al }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}al\textquotesingle{}}\NormalTok{)}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ dist.normal(}\OperatorTok{{-}}\FloatTok{1.5}\NormalTok{, }\DecValTok{1}\NormalTok{, name}\OperatorTok{=}\StringTok{\textquotesingle{}ap\textquotesingle{}}\NormalTok{)}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ expit(ap)}
\NormalTok{    lambda\_ }\OperatorTok{=}\NormalTok{ jnp.exp(al)}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, ZeroInflatedPoisson(p, lambda\_), obs}\OperatorTok{=}\NormalTok{y)}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Define parameters}
\NormalTok{prob\_drink }\OtherTok{=} \FloatTok{0.2}  \CommentTok{\# 20\% of days}
\NormalTok{rate\_work }\OtherTok{=} \DecValTok{1}     \CommentTok{\# average 1 manuscript per day}
\CommentTok{\# sample one year of production}
\NormalTok{N }\OtherTok{=} \FunctionTok{as.integer}\NormalTok{(}\DecValTok{365}\NormalTok{)}
\NormalTok{drink }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{binomial}\NormalTok{(}\AttributeTok{total\_count =} \FunctionTok{as.integer}\NormalTok{(}\DecValTok{1}\NormalTok{), }\AttributeTok{probs =}\NormalTok{ prob\_drink, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(N), }\AttributeTok{sample =}\NormalTok{ T ) }\CommentTok{\# An example of sampling a distribution with BI}
\NormalTok{y }\OtherTok{=}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ drink) }\SpecialCharTok{*}\NormalTok{  bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{poisson}\NormalTok{(rate\_work, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(N), }\AttributeTok{sample =}\NormalTok{ T)}
\NormalTok{data }\OtherTok{=} \FunctionTok{list}\NormalTok{()}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{y }\OtherTok{=}\NormalTok{ y }
\NormalTok{m}\SpecialCharTok{$}\NormalTok{data\_on\_model }\OtherTok{=}\NormalTok{ data}
\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y)\{}
\NormalTok{  al }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}al\textquotesingle{}}\NormalTok{)}
\NormalTok{  ap }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}ap\textquotesingle{}}\NormalTok{)}
\NormalTok{  p }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{jax}\SpecialCharTok{$}\NormalTok{scipy}\SpecialCharTok{$}\NormalTok{special}\SpecialCharTok{$}\FunctionTok{expit}\NormalTok{(al)}
\NormalTok{  lambda\_ }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{jnp}\SpecialCharTok{$}\FunctionTok{exp}\NormalTok{(al)}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{ZeroInflatedPoisson}\NormalTok{(p, lambda\_), }\AttributeTok{obs=}\NormalTok{y)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\chapter{Mathematical Details}\label{mathematical-details-10}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-6}

We model the relationship between the predictor variables \(X\) and the
count outcome variable \(Y\) using two components: 1. A logistic
regression model to predict the probability of an excess zero. 2. A
count model (e.g., Poisson or Negative Binomial) to predict the count
outcome.

The overall model can be represented as follows:

\[
\begin{aligned}
& \text{logit}(\pi) = \alpha_\pi + \beta_\pi X \\
& \text{log}(\lambda) = \alpha_\lambda + \beta_\lambda X\\
& Y \sim \begin{cases} 
0 & \text{with probability } \pi \\
\text{CountModel}(\lambda) & \text{with probability } (1 - \pi) 
\end{cases}
\end{aligned}
\]

Where:

\begin{itemize}
\item
  \(\pi\) is the probability of an excess zero.
\item
  \(\lambda\) is the mean rate parameter of the count model.
\item
  \(\alpha_\pi\) and \(\beta_\pi\) are respectively the intercept and
  the regression coefficient for the logistic model.
\item
  \(\alpha_\lambda\) and \(\beta_\lambda\) are respectively the
  regression coefficients for the count model.
\item
  \(X\) are the independent variables.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-6}

In the Bayesian formulation, we define each parameter with
\phantomsection\label{prior}{{priors üõà}}. We can express the Bayesian
regression model accounting for prior distribution as follows:

\[
ùëå\sim ZIPoisson(\pi,\lambda)
\]

\[
\text{logit}(\pi) = \alpha_\pi + \beta_\pi X
\]

\[
\text{log}(\lambda) = \alpha_\lambda + \beta_\lambda X
\]

\[
\alpha_\pi \sim \text{Normal}(0,1)
\]

\[
\beta_\pi \sim \text{Normal}(0,1)
\]

\[
\alpha_\lambda \sim \text{Normal}(0,1)
\]

\[
\beta_\lambda \sim \text{Normal}(0,1)
\]

Where:

\begin{itemize}
\item
  \(\pi\) is the probability of an excess zero.
\item
  \(\lambda\) is the mean rate parameter of the count model.
\item
  \(\alpha_\pi\) and \(\beta_\pi\) are respectively the intercept and
  the regression coefficient for the logistic model.
\item
  \(\alpha_\lambda\) and \(\beta_\lambda\) are respectively the
  regression coefficients for the count model.
\item
  \(X\) are the independent variables.
\end{itemize}

\section{Reference(s)}\label{references-10}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Varying intercepts}\label{varying-intercepts}

\section{General Principles}\label{general-principles-11}

To model the relationship between predictor variables and an independent
variable while allowing for different intercepts across groups or
clusters, we can use a \emph{Varying Intercepts} model. This approach is
particularly useful when data is grouped (e.g., by subject, location, or
time period) and we expect the baseline level of the outcome to vary
across these groups.

\section{Considerations}\label{considerations-11}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{1.\%20Linear\%20Regression\%20for\%20continuous\%20variable.qmd}{Regression
  for continuous variable}.
\item
  The main idea of varying intercepts is to generate an intercept for
  each group, allowing each group to start at different levels. Thus,
  the intercept \(\beta\) is defined based on the \(k\) declared groups.
\item
  Each intercept have is own \emph{Normal distribution} -i.e.~a
  \phantomsection\label{hyperP}{{hyper-prior üõà}}
\end{itemize}

-In the code below, the \emph{hyper-prior} is \texttt{a\_bar}.

\end{tcolorbox}

\section{Example}\label{example-11}

Below is an example code snippet demonstrating Bayesian regression with
varying intercepts using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}

\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.data(}\StringTok{\textquotesingle{}../data/reedfrogs.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m.df[}\StringTok{"tank"}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.arange(m.df.shape[}\DecValTok{0}\NormalTok{])}
\NormalTok{tank }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"tank"}\NormalTok{].astype(}\StringTok{\textquotesingle{}int32\textquotesingle{}}\NormalTok{).values)}
\NormalTok{density }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"density"}\NormalTok{].astype(}\StringTok{\textquotesingle{}float32\textquotesingle{}}\NormalTok{).values)}
\NormalTok{surv }\OperatorTok{=}\NormalTok{ jnp.array(m.df[}\StringTok{"surv"}\NormalTok{].astype(}\StringTok{\textquotesingle{}int32\textquotesingle{}}\NormalTok{).values)}
\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    tank }\OperatorTok{=}\NormalTok{ tank,}
\NormalTok{    surv }\OperatorTok{=}\NormalTok{ surv}
\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(tank, surv):}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ dist.exponential( }\DecValTok{1}\NormalTok{,  name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    a\_bar }\OperatorTok{=}\NormalTok{ dist.normal( }\FloatTok{0.}\NormalTok{, }\FloatTok{1.5}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}a\_bar\textquotesingle{}}\NormalTok{)}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ dist.normal( a\_bar, sigma, shape}\OperatorTok{=}\NormalTok{ [}\DecValTok{48}\NormalTok{], name }\OperatorTok{=} \StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{)}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ jnp.squeeze(alpha[tank])}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Binomial(total\_count }\OperatorTok{=}\NormalTok{ density, logits }\OperatorTok{=}\NormalTok{ p), obs}\OperatorTok{=}\NormalTok{surv)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{R}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(reticulate)}
\NormalTok{bi }\OtherTok{\textless{}{-}} \FunctionTok{import}\NormalTok{(}\StringTok{"main"}\NormalTok{)}

\CommentTok{\# Setup device {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\FunctionTok{bi}\NormalTok{(}\AttributeTok{platform=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Import data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data}\NormalTok{(}\StringTok{\textquotesingle{}../data/reedfrogs.csv\textquotesingle{}}\NormalTok{, }\AttributeTok{sep=}\StringTok{\textquotesingle{};\textquotesingle{}}\NormalTok{) }
\NormalTok{m}\SpecialCharTok{$}\NormalTok{df}\SpecialCharTok{$}\NormalTok{tank }\OtherTok{=} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{df)}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{data\_to\_model}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\StringTok{\textquotesingle{}tank\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}surv\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}density\textquotesingle{}}\NormalTok{))}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{data\_on\_model}\SpecialCharTok{$}\NormalTok{tank }\OtherTok{=}\NormalTok{ m}\SpecialCharTok{$}\NormalTok{data\_on\_model}\SpecialCharTok{$}\NormalTok{tank}\SpecialCharTok{$}\FunctionTok{astype}\NormalTok{(bi}\SpecialCharTok{$}\NormalTok{jnp}\SpecialCharTok{$}\NormalTok{int32)}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{data\_on\_model}\SpecialCharTok{$}\NormalTok{surv }\OtherTok{=}\NormalTok{ m}\SpecialCharTok{$}\NormalTok{data\_on\_model}\SpecialCharTok{$}\NormalTok{surv}\SpecialCharTok{$}\FunctionTok{astype}\NormalTok{(bi}\SpecialCharTok{$}\NormalTok{jnp}\SpecialCharTok{$}\NormalTok{int32)}
\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{model }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(tank, surv, density)\{}
\NormalTok{  sigma }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{exponential}\NormalTok{( }\DecValTok{1}\NormalTok{,  }\AttributeTok{name =} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{  a\_bar }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{1.5}\NormalTok{, }\AttributeTok{name=}\StringTok{\textquotesingle{}a\_bar\textquotesingle{}}\NormalTok{)}
\NormalTok{  alpha }\OtherTok{=}\NormalTok{ bi}\SpecialCharTok{$}\NormalTok{dist}\SpecialCharTok{$}\FunctionTok{normal}\NormalTok{(a\_bar, sigma, }\AttributeTok{name=}\StringTok{\textquotesingle{}alpha\textquotesingle{}}\NormalTok{, }\AttributeTok{shape =} \FunctionTok{tuple}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(}\DecValTok{48}\NormalTok{)))}
\NormalTok{  p }\OtherTok{=}\NormalTok{ alpha[tank]}
\NormalTok{  bi}\SpecialCharTok{$}\FunctionTok{lk}\NormalTok{(}\StringTok{"y"}\NormalTok{, bi}\SpecialCharTok{$}\FunctionTok{Binomial}\NormalTok{(}\AttributeTok{total\_count =}\NormalTok{ density, }\AttributeTok{logits =}\NormalTok{ p), }\AttributeTok{obs=}\NormalTok{surv)}
\NormalTok{\}}

\CommentTok{\# Run MCMC {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\FunctionTok{run}\NormalTok{(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m}\SpecialCharTok{$}\NormalTok{sampler}\SpecialCharTok{$}\FunctionTok{print\_summary}\NormalTok{(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-11}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula-4}

We model the relationship between the independent variables \emph{X} and
the outcome variable \emph{Y} with varying intercepts \(\alpha\) for
each group \emph{k} using the following equation:

\[
Y_{ik} = \alpha_k + \beta X_{ik} + \sigma
\]

Where:

\begin{itemize}
\item
  \(Y_{ik}\) is the outcome variable for observation \emph{i} in group
  \emph{k}.
\item
  \(\alpha_k\) is the varying intercept for group \emph{k}.
\item
  \(X_{ik}\) is the independent variables for observation \emph{i} in
  group \emph{k}.
\item
  \(\beta\) is the regression coefficients term.
\item
  \(\sigma\) is the error term, typically assumed to be normally
  distributed and positive.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
model}}{Bayesian model}}\label{bayesian-model-4}

We can express the Bayesian regression model accounting for prior
distribution as follows:

\[
Y_{ik} = Normal(\mu_{ik}, \sigma)
\] \[
\mu_{ik} = \alpha_j + \beta X_{ik} + \sigma 
\] \[
\alpha_k \sim \text{Normal}(\mu_{\alpha_k}, \sigma_{\alpha_k}) 
\] \[
\beta \sim \text{Normal}(0, 1)
\] \[
\sigma \sim \text{Exponential}(1)
\] \[
\mu_{\alpha_k} \sim \text{Normal}(0, 1)
\] \[
\sigma_{\alpha_k} \sim \text{Exponential}(1)
\]

Where:

\begin{itemize}
\item
  \(Y_{ij}\) is the likelihood function for the outcome variable.
\item
  \(\alpha_k\) is the varying intercepts across groups.
\item
  \(\mu_{\alpha_k}\) is the overall mean intercept.
\item
  \(\sigma_{\alpha_k}\) is the variance of the intercepts across groups.
\item
  \(\beta\) is the prior distributions for the regression coefficients.
\item
  \(\sigma\) is the prior distributions for the error term.
\end{itemize}

\section{Notes}\label{notes-4}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  We can apply multiple variables similarly as
  \href{./2.\%20Multiple\%20Regression\%20for\%20Continuous\%20Variables.qmd}{chapter
  2}.
\item
  We can apply interaction terms similarly as
  \href{/3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{chapter
  3}.
\item
  We can apply caterogical variables similarly as
  \href{4.\%20Categorical\%20variable.qmd}{chapter 4}.
\item
  We can apply varying intercepts with any distribution developped in
  previous chapters.
\end{itemize}

\end{tcolorbox}

\section{Reference(s)}\label{references-11}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Varying slopes}\label{varying-slopes}

\section{General Principles}\label{general-principles-12}

To model the relationship between predictor variables and an independent
variable while allowing for varying effects across groups or clusters,
we use a \emph{Varying slopes} model.

This approach is useful when we expect the relationship between
predictors and the independent variable to differ across groups (e.g.,
different slopes for different subjects, locations, or time
periods).This allow every unit in the data to have its own unique
response to any treatment or exposure or event, while also improving
estimates via pooling.

\section{Considerations}\label{considerations-12}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\item
  We have the same considerations as for
  \href{12.\%20Varying\%20intercepts.qmd}{12. Varying interceps}.
\item
  The idea is pretty similar to categorical models, where a slope is
  specified for each category. However, here, we also estimate
  relationships between different groups. This leads to a different
  mathematical approach, as to model these relationships between groups,
  we model a \phantomsection\label{cov}{{ matrix of covariance üõà}}.
\item
  The covariance matrix requiere a correlation matris distribution which
  is modeleld using a \(LKJcorr\) distribution that hold a parameter
  \(Œ∑\). \(Œ∑\) is ussually set to 2 to define a weakly informative prior
  that is skeptical of extreme correlations near ‚àí1 or 1. When we use
  LKJ- corr(1), the prior is flat over all valid correlation matrices.
  When the value is greater than 1, then extreme correlations are less
  likely.
\item
  The Half-Cauchy distribution is used when modeling the covariance
  matrix to specify strictly positive values for the diagonal of the
  covariance matrix, ensuring positive variances.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-12}

Below is an example code snippet demonstrating Bayesian regression with
varying effects:

\subsection{Simulated data}\label{simulated-data}

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}
\NormalTok{m.data(}\StringTok{\textquotesingle{}Sim data multivariatenormal.csv\textquotesingle{}}\NormalTok{, sep}\OperatorTok{=}\StringTok{\textquotesingle{},\textquotesingle{}}\NormalTok{) }
\NormalTok{m.data.to\_model([}\StringTok{\textquotesingle{}cafe\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}wait\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}N\_cafes\textquotesingle{}}\NormalTok{])}

\KeywordTok{def}\NormalTok{ model(cafe, wait, N\_cafes):}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{) }\CommentTok{\#Standard Normal Vector }
\NormalTok{    b }\OperatorTok{=}\NormalTok{ dist.normal(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{) }\CommentTok{\# Standard Normal Vector }
\NormalTok{    sigma\_cafe }\OperatorTok{=}\NormalTok{ dist.exponential(}\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{[}\DecValTok{2}\NormalTok{], name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\_cafe\textquotesingle{}}\NormalTok{)}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ dist.exponential( }\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    Rho }\OperatorTok{=}\NormalTok{ dist.lkj(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}Rho\textquotesingle{}}\NormalTok{) }\CommentTok{\# Cholesky Factor}
    \CommentTok{\# Applies the correlation structure between the variables.}
    \CommentTok{\# Scaling the Cholesky Factor by the standard deviations.}
\NormalTok{    cov }\OperatorTok{=}\NormalTok{ jnp.outer(sigma\_cafe, sigma\_cafe) }\OperatorTok{*}\NormalTok{ Rho }\CommentTok{\# In a multivariate normal distribution, we not only have correlations (from sr\_L), but also individual standard deviations for each variable (from sr\_sigma). The diag\_pre\_multiply operation ensures that each variable\textquotesingle{}s correlation structure is properly scaled by its standard deviation. This makes it possible to account for both correlations and individual variability when generating samples.}
    \CommentTok{\#This operation applies the correlation and standard deviation structure (encoded in scaled\_sr\_L) to the standard normal variables sr\_raw. The result is a sample from a multivariate normal distribution that respects both the correlations between variables and the individual standard deviations.}
\NormalTok{    a\_cafe\_b\_cafe }\OperatorTok{=}\NormalTok{ dist.multivariatenormal(jnp.stack([a, b]), cov, shape }\OperatorTok{=}\NormalTok{ [N\_cafes], name }\OperatorTok{=} \StringTok{\textquotesingle{}a\_cafe\textquotesingle{}}\NormalTok{)    }

\NormalTok{    a\_cafe, b\_cafe }\OperatorTok{=}\NormalTok{ a\_cafe\_b\_cafe[:, }\DecValTok{0}\NormalTok{], a\_cafe\_b\_cafe[:, }\DecValTok{1}\NormalTok{]}
\NormalTok{    mu }\OperatorTok{=}\NormalTok{ a\_cafe[cafe] }\OperatorTok{+}\NormalTok{ b\_cafe[cafe] }\OperatorTok{*}\NormalTok{ afternoon}
\NormalTok{    lk(}\StringTok{"y"}\NormalTok{, Normal(mu, sigma), obs}\OperatorTok{=}\NormalTok{wait)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{R}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-12}

\section{Mathematical Details}\label{mathematical-details-13}

\subsection{\texorpdfstring{\emph{Formula}}{Formula}}\label{formula-5}

We model the relationship between the independent variable \(X\) and the
outcome variable \emph{Y} with varying intercepts (\(\alpha\)) and
varying slopes (\(\beta\)) for each group (\emph{k}) using the following
equation:

\[
Y_{ik} = \alpha_k + \beta_k X_{ik} + \sigma
\]

Where: - \(Y_{ik}\) is the outcome variable for observation \emph{i} in
group \emph{k}.

\begin{itemize}
\item
  \(X_{ik}\) is the independent variables for observation \emph{i} in
  group \emph{k}.
\item
  \(\alpha_k\) is the varying intercept for group \emph{k}.
\item
  \(\beta_k\) is the varying regression coefficients for group \emph{k}.
\item
  \(\sigma\) is the error term, assumed to be strictly positive.
\end{itemize}

\subsection{\texorpdfstring{\emph{Bayesian
model}}{Bayesian model}}\label{bayesian-model-5}

We can express the Bayesian regression model accounting for prior
distribution as follows:

\[
Y_{ik} \sim \text{Normal}(\mu_{ik} , \sigma)
\] \[
\mu_{ik} = \alpha_k + \beta_k X_{ik} + \sigma 
\] \[
\alpha_k \sim Normal(0,1) 
\] \[
\beta_k \sim Normal(0,1)
\] \[
\sigma \sim Exponential(0,1)
\]

The varying intercepts slopes (\(\alpha_k\)) and (\(\beta_k\)) are
modeled using a \emph{Multivariate Normal distribution}:

\[ 
\begin{pmatrix} 
\alpha_k \\ 
\beta_k 
\end{pmatrix} \sim \text{MultivariateNormal}\left( 
\begin{pmatrix} 
0 \\ 
0 
\end{pmatrix}, 
\begin{pmatrix} 
\sigma_\alpha^2 & \sigma_\pi \sigma_{\alpha\rho} \\ 
\sigma_\alpha \sigma_{\pi\rho} & \sigma_\pi 
\end{pmatrix} 
\right) 
\]

Where:

\begin{itemize}
\item
  \(\left(\begin{array}{cc} 0 \\0\end{array}\right)\), is the prior for
  average intercept.
\item
  \(\left(\begin{array}{cc} \sigma_\alpha^2 & \sigma_\pi\sigma_{\alpha\rho} \\ \sigma_\alpha\sigma_{\pi\rho} & \sigma_\pi \end{array}\right)\)
  is is the covariance matrix which specifies the variance and
  covariance of \(\alpha_k\) and \(\beta_k\),
\item
  where: - \(\sigma_\alpha^2\) The variance of \(\alpha_k\).
\item
  \(\sigma_\pi^2\) The variance of \(\beta_k\).
\item
  \(\sigma_\pi\sigma_{\alpha\rho}\) and
  \(\sigma_\alpha\sigma_{\pi\rho}\) The covariance between \(\alpha_k\)
  and \(\beta_k\)
\end{itemize}

For computational reasons, it is often better to implement a
\phantomsection\label{centerRF}{{centered version of the varying
intercept üõà}} that is equivalent to the \emph{Multivariate Normal
distribution} approach:

\[
\left(\begin{array}{cc} \alpha_k \\ \beta_k\end{array}\right)
 \sim 
\left(\begin{array}{cc} 
\sigma_\alpha\\
\sigma_\pi
\end{array}\right) \circ 
L *
\left(\begin{array}{cc} 
\widehat{\alpha}_k \\
\widehat{\pi}_k
\end{array}\right)
\]

\begin{itemize}
\item
  Where:

  \begin{itemize}
  \item
    \(\sigma_\alpha \sim Exponential(1)\) bewing the prior standard
    deviation among intercepts.
  \item
    \(\sigma_\beta \sim Exponential(1)\) bewing the prior standard
    deviation among slopes.
  \item
    \(L \sim LKJcorr(Œ∑)\) bewing the prior for the correlation matrix
    using the \phantomsection\label{chol}{{Cholesky Factor üõà}}.
  \end{itemize}
\end{itemize}

The full cetered version of the model is thus :

\[
Y_{i} \sim \text{Normal}(\mu_k , \sigma) \\
\]

\[
\mu_k =   \alpha_k + \beta_i X_i \\
\]

\[
\left(\begin{array}{cc} \alpha_k \\ \beta_k\end{array}\right)
 \sim 
\left(\begin{array}{cc} 
\sigma_\alpha\\
\sigma_\pi
\end{array}\right) \circ 
L *
\left(\begin{array}{cc} 
\widehat{\alpha}_k \\
\widehat{\pi}_k
\end{array}\right)
\]

\[
\alpha \sim Normal(0,1)
\] \[
\beta \sim Normal(0,1)
\] \[
\sigma_\alpha \sim Exponential(1)
\] \[
\sigma_\pi \sim Exponential(1)
\] \[
L \sim LKJcorr(2)
\]

\section{Notes}\label{notes-5}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\tightlist
\item
  We can apply multivariate model similarly as
  \href{./2.\%20Multiple\%20Regression\%20for\%20Continuous\%20Variables.qmd}{chapter
  2}. In this case, we apply the same principle, but with a covariance
  matrix of a dimension equal to the number of varying slopes we define.
  For example, if we want to generate random slopes for \(i\) actors in
  a model with two independent variables \(X_1\) and \(X_2\), we can
  define the formula as follows:
\end{itemize}

\[
p(Y_{i} |\mu_i , \sigma) \sim \text{Normal}(\mu_i , \sigma) 
\]

\[
\mu_i =   \alpha_i + \beta_{1i} X_{1i}  + \beta_{1i} X_{2i} 
\]

\[ 
\begin{pmatrix} 
\alpha_{i}\\ 
\beta_{1i}\\ 
\beta_{2i} 
\end{pmatrix} 
\sim \begin{pmatrix} 
\sigma_{\alpha}\\ 
\sigma_{\pi}\\ 
\sigma_{\gamma} 
\end{pmatrix} \circ L \cdot \begin{pmatrix} 
\widehat{\alpha}_{k} \\ 
\widehat{\pi}_{k} \\ 
\widehat{\gamma}_{k} 
\end{pmatrix} 
\]

\[
\sigma_{\alpha} \sim Exponential(1)
\] \[
\sigma_{\pi} \sim Exponential(1)
\] \[
\sigma_{\gamma} \sim Exponential(1) 
\] \[
L \sim LKJcorr(2)
\]

\begin{itemize}
\item
  We can apply interaction terms similarly as
  \href{/3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{chapter
  3}.
\item
  We can apply caterogical variables similarly as
  \href{4.\%20Categorical\%20variable.qmd}{chapter 4}.
\item
  We can apply varying slopes with any distribution presented in
  previous chapters.
\item
  For more than two varying effects we apply the same principel but with
  a covariance matrix for each varying effect that are summed to
  gernerat the varying intercept and slope. For exmaple, if we want to
  generate random slopes for \(i\) actors, and \(k\) groups we can
  define the formula as follow:
\end{itemize}

\[
p(Y_{i} |\mu_i , \sigma) \sim \text{Normal}(\mu_i , \sigma) \\
\]

\[
\mu_i =   \alpha_i + \beta_{i} X_i 
\] \[
\alpha_i = \alpha + \alpha_{actor[i]} + \alpha_{group[i]}
\] \[
\beta_{i} = \beta + \beta_{actor[i]} + \beta_{group[i]} 
\]

\[
\alpha \sim Normal(0,1)
\] \[
\beta \sim Normal(0,1) 
\]

\[ 
\begin{pmatrix} 
\alpha_{\text{actor}} \\ 
\beta_{\text{actor}} 
\end{pmatrix} 
\sim 
\begin{pmatrix} 
\sigma_{\alpha a} \\ 
\sigma_{\pi a} 
\end{pmatrix} \circ L_a \cdot \begin{pmatrix} 
\widehat{\alpha}_{ka} \\ 
\widehat{\pi}_{ka} 
\end{pmatrix} 
\]

\[
\sigma_{\alpha a} \sim Exponential(1)
\] \[
\sigma_{\pi a} \sim Exponential(1)
\] \[
L_{a} \sim LKJcorr(2)
\]

\[ 
\begin{pmatrix} 
\alpha_{\text{group}} \\ 
\beta_{\text{group}} 
\end{pmatrix} 
\sim  
\begin{pmatrix} 
\sigma_{\alpha g} \\ 
\sigma_{\pi g} 
\end{pmatrix} \circ L_g \cdot 
\begin{pmatrix} 
\widehat{\alpha}_{kg} \\ 
\widehat{\pi}_{kg} 
\end{pmatrix} 
\]

\[
\sigma_{\alpha g} \sim Exponential(1)
\] \[
\sigma_{\pi g} \sim Exponential(1) 
\] \[
L_{g} \sim LKJcorr(2)
\]

\begin{itemize}
\tightlist
\item
  Bellow the formula and the code snipset for a Binomial multivariate
  model with interaction between two independent variables \(X_1\) and
  \(X_2\) and multiples varying effects for each actor and each group:
\end{itemize}

\[
p(Y_{i} |n , p_i) \sim \text{Binomial}(n = 1, p_i) \\
\]

\[
logit{p_i}=   \alpha_i + (\beta_{1i}  + \beta_{2i} X_{2i})  X_{1i}
\] \[
\alpha_i = \alpha + \alpha_{actor[i]} + \alpha_{group[i]}
\] \[
\beta_{1i} = \beta + \beta_{1 actor[i]} + \beta_{ group[i]}
\] \[
\beta_{2i} = \beta + \beta_{2 actor[i]} + \beta_{2 group[i]}
\]

\[
\alpha \sim Normal(0,1)
\] \[
\beta \sim Normal(0,1)
\]

\[ 
\begin{pmatrix} 
\alpha_{\text{actor}} \\ 
\beta_{1 \, \text{actor}} \\ 
\beta_{2 \, \text{actor}} 
\end{pmatrix} 
\sim  
\begin{pmatrix} 
\sigma_{\alpha a} \\ 
\sigma_{\pi a} \\ 
\sigma_{\gamma a} 
\end{pmatrix} \circ L_a \cdot 
\begin{pmatrix} 
\widehat{\alpha}_{ka} \\ 
\widehat{\pi}_{ka} \\ 
\widehat{\gamma}_{ka} 
\end{pmatrix} 
\]

\[
\sigma_{\alpha a} \sim Exponential(1) 
\]

\[
\sigma_{\pi a} \sim Exponential(1) 
\] \[
\sigma_{\gamma a} \sim Exponential(1) 
\] \[
L_{a} \sim LKJcorr(2)
\]

\[ 
\begin{pmatrix} 
\alpha_{\text{group}} \\ 
\beta_{1 \, \text{group}} \\ 
\beta_{2 \, \text{group}} 
\end{pmatrix} 
\sim  
\begin{pmatrix} 
\sigma_{\alpha g} \\ 
\sigma_{\pi g} \\ 
\sigma_{\gamma g} 
\end{pmatrix} \circ L_g \cdot 
\begin{pmatrix} 
\widehat{\alpha}_{kg} \\ 
\widehat{\pi}_{kg} \\ 
\widehat{\gamma}_{kg} 
\end{pmatrix} 
\]

\[
\sigma_{\alpha g} \sim Exponential(1)
\] \[
\sigma_{\pi g} \sim Exponential(1) 
\] \[
\sigma_{\gamma g} \sim Exponential(1)
\] \[
L_{g} \sim LKJcorr(2)
\]

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}
\CommentTok{\# Import data}
\NormalTok{m.read\_csv(}\StringTok{"../data/chimpanzees.csv"}\NormalTok{, sep}\OperatorTok{=}\StringTok{";"}\NormalTok{)}
\NormalTok{m.df[}\StringTok{"block\_id"}\NormalTok{] }\OperatorTok{=}\NormalTok{ m.df.block}
\NormalTok{m.df[}\StringTok{"treatment"}\NormalTok{] }\OperatorTok{=} \DecValTok{1} \OperatorTok{+}\NormalTok{ m.df.prosoc\_left }\OperatorTok{+} \DecValTok{2} \OperatorTok{*}\NormalTok{ m.df.condition}
\NormalTok{m.data\_to\_model([}\StringTok{\textquotesingle{}pulled\_left\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}treatment\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}actor\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}block\_id\textquotesingle{}}\NormalTok{])}


\KeywordTok{def}\NormalTok{ model(tid, actor, block\_id, L}\OperatorTok{=}\VariableTok{None}\NormalTok{, link}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \CommentTok{\# fixed priors}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}g\textquotesingle{}}\NormalTok{, shape }\OperatorTok{=}\NormalTok{ (}\DecValTok{4}\NormalTok{,))}
\NormalTok{    sigma\_actor }\OperatorTok{=}\NormalTok{ dist.exponential(}\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\_actor\textquotesingle{}}\NormalTok{, shape }\OperatorTok{=}\NormalTok{ (}\DecValTok{4}\NormalTok{,))}
\NormalTok{    L\_Rho\_actor }\OperatorTok{=}\NormalTok{ dist.lkjcholesky(}\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, name }\OperatorTok{=} \StringTok{"L\_Rho\_actor"}\NormalTok{)}
\NormalTok{    sigma\_block }\OperatorTok{=}\NormalTok{ dist.exponential(}\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{"sigma\_block"}\NormalTok{, shape }\OperatorTok{=}\NormalTok{ (}\DecValTok{4}\NormalTok{,))}
\NormalTok{    L\_Rho\_block }\OperatorTok{=}\NormalTok{ dist.lkjcholesky(}\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, name }\OperatorTok{=} \StringTok{"L\_Rho\_block"}\NormalTok{)}

    \CommentTok{\# adaptive priors {-} non{-}centered}
\NormalTok{    z\_actor }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{"z\_actor"}\NormalTok{, shape }\OperatorTok{=}\NormalTok{ (}\DecValTok{4}\NormalTok{,}\DecValTok{7}\NormalTok{))}
\NormalTok{    z\_block }\OperatorTok{=}\NormalTok{ dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, name }\OperatorTok{=} \StringTok{"z\_block"}\NormalTok{, shape }\OperatorTok{=}\NormalTok{ (}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{    alpha }\OperatorTok{=}\NormalTok{ deterministic(}
        \StringTok{"alpha"}\NormalTok{, ((sigma\_actor[..., }\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ L\_Rho\_actor) }\OperatorTok{@}\NormalTok{ z\_actor).T}
\NormalTok{    )}
\NormalTok{    beta }\OperatorTok{=}\NormalTok{ deterministic(}
        \StringTok{"beta"}\NormalTok{, ((sigma\_block[..., }\VariableTok{None}\NormalTok{] }\OperatorTok{*}\NormalTok{ L\_Rho\_block) }\OperatorTok{@}\NormalTok{ z\_block).T}
\NormalTok{    )}

\NormalTok{    logit\_p }\OperatorTok{=}\NormalTok{ g[tid] }\OperatorTok{+}\NormalTok{ alpha[actor, tid] }\OperatorTok{+}\NormalTok{ beta[block\_id, tid]}
\NormalTok{    dist(}\StringTok{"L"}\NormalTok{, dist.Binomial(logits}\OperatorTok{=}\NormalTok{logit\_p), obs}\OperatorTok{=}\NormalTok{L)}

    \CommentTok{\# compute ordinary correlation matrixes from Cholesky factors}
    \ControlFlowTok{if}\NormalTok{ link:}
\NormalTok{        deterministic(}\StringTok{"Rho\_actor"}\NormalTok{, L\_Rho\_actor }\OperatorTok{@}\NormalTok{ L\_Rho\_actor.T)}
\NormalTok{        deterministic(}\StringTok{"Rho\_block"}\NormalTok{, L\_Rho\_block }\OperatorTok{@}\NormalTok{ L\_Rho\_block.T)}
\NormalTok{        deterministic(}\StringTok{"p"}\NormalTok{, expit(logit\_p))}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\section{Reference(s)}\label{references-12}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Gaussian processes}\label{gaussian-processes}

\section{General Principles}\label{general-principles-13}

\section{Considerations}\label{considerations-13}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-13}

Below is an example code snippet demonstrating Bayesian Gaussian
processes model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-14}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-7}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-7}

\section{Notes}\label{notes-6}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-13}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Measuring error}\label{measuring-error}

\section{General Principles}\label{general-principles-14}

\section{Considerations}\label{considerations-14}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-14}

Below is an example code snippet demonstrating Bayesian Measuring error
model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-15}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-8}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-8}

\section{Notes}\label{notes-7}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-14}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Missing data}\label{missing-data}

\section{General Principles}\label{general-principles-15}

\section{Considerations}\label{considerations-15}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-15}

Below is an example code snippet demonstrating Bayesian Missing data
model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-16}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-9}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-9}

\section{Notes}\label{notes-8}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-15}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Latent Variables}\label{latent-variables}

\section{General Principles}\label{general-principles-16}

In some scenarios, the observed data does not directly reflect the
underlying structure or factors influencing the outcome. Instead,
\emph{latent variables} --- variables that are not directly observed but
inferred from the data --- can help model this hidden structure. These
latent variables capture unobserved factors that affect the relationship
between predictors (\emph{X}) and the outcome (\emph{Y}).

We model the relationship between the predictor variables (\emph{X}) and
the outcome variable (\emph{Y}) with a latent variable (\emph{Z}) as
follows:

\[
Y = f(X, Z) + \epsilon
\]

Where: - \emph{Y} is the observed outcome variable. - \emph{X} is the
observed predictor variable(s). - \emph{Z} is the latent (unobserved)
variable, which we aim to infer. - \emph{f(X, Z)} is the function that
relates \emph{X} and \emph{Z} to \emph{Y}. - \emph{\epsilon} is the
error term, typically assumed to be normally distributed with mean 0 and
variance \emph{\sigma\^{}2}.

The latent variable \emph{Z} can represent various phenomena, such as
group-level effects, time-varying trends, or individual-level factors,
that are not captured by the observed predictors alone.

\section{Considerations}\label{considerations-16}

In Bayesian regression with latent variables, we consider the
uncertainty in both the observed and latent variables. We declare prior
distributions for the latent variables, in addition to the usual priors
for regression coefficients and intercepts. These latent variables are
often modeled using Gaussian distributions (\emph{Normal} priors) or
more flexible distributions such as \emph{Multivariate Normal} for
correlations among the latent variables.

The goal is to infer the posterior distribution over both the parameters
and the latent variables, given the observed data.

\section{Example}\label{example-16}

Below is an example code snippet demonstrating Bayesian regression with
latent variables using TensorFlow Probability:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ main }\ImportTok{import}\OperatorTok{*}
\CommentTok{\# Setup device{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m }\OperatorTok{=}\NormalTok{ bi(platform}\OperatorTok{=}\StringTok{\textquotesingle{}cpu\textquotesingle{}}\NormalTok{)}

\CommentTok{\# Data Simulation {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{NY }\OperatorTok{=} \DecValTok{4}  \CommentTok{\# Number of dependent variables or outcomes (e.g., dimensions for latent variables)}
\NormalTok{NV }\OperatorTok{=} \DecValTok{8}  \CommentTok{\# Number of observations or individual{-}level data points (e.g., subjects)}

\CommentTok{\# Initialize the matrix Y2 with shape (NV, NY) filled with NaN values, to be filled later}
\NormalTok{Y2 }\OperatorTok{=}\NormalTok{ np.full((NV, NY), np.nan)}

\CommentTok{\# Generate the means and offsets for the data}
\CommentTok{\# means: Generate random normal means for each of the NY outcomes}
\CommentTok{\# offsets: Generate random normal offsets for each of the NV observations}
\NormalTok{means }\OperatorTok{=}\NormalTok{ bi.distribution.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(NY,), sample }\OperatorTok{=} \VariableTok{True}\NormalTok{, seed }\OperatorTok{=} \DecValTok{10}\NormalTok{)}
\NormalTok{offsets }\OperatorTok{=}\NormalTok{ bi.distribution.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(NV,}\DecValTok{1}\NormalTok{), sample }\OperatorTok{=} \VariableTok{True}\NormalTok{, seed }\OperatorTok{=} \DecValTok{20}\NormalTok{)}

\CommentTok{\# Fill the matrix Y2 with simulated data based on the generated means and offsets}
\CommentTok{\# Each observation (i) is the sum of an individual{-}specific offset and an outcome{-}specific mean}
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(NV):}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(NY):}
\NormalTok{        Y2[i, k] }\OperatorTok{=}\NormalTok{ means[k] }\OperatorTok{+}\NormalTok{ offsets[i]}

\CommentTok{\# Simulate individual{-}level random effects (e.g., random slopes or intercepts)}
\CommentTok{\# b\_individual: A matrix of size (N, K) where N is the number of individuals and K is the number of covariates}
\NormalTok{b\_individual }\OperatorTok{=}\NormalTok{ bi.distribution.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{N, K), sample }\OperatorTok{=} \VariableTok{True}\NormalTok{, seed }\OperatorTok{=} \DecValTok{0}\NormalTok{)}

\CommentTok{\# mu: Add an additional effect \textquotesingle{}a\textquotesingle{} to the individual{-}level random effects \textquotesingle{}b\_individual\textquotesingle{}}
\CommentTok{\# \textquotesingle{}a\textquotesingle{} could represent a population{-}level effect or a baseline}
\NormalTok{mu }\OperatorTok{=}\NormalTok{ b\_individual }\OperatorTok{+}\NormalTok{ a}

\CommentTok{\# Convert Y2 to a JAX array for further computation in a JAX{-}based framework}
\NormalTok{Y2 }\OperatorTok{=}\NormalTok{ jnp.array(Y2)}


\CommentTok{\# Set data {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{dat }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    NY }\OperatorTok{=}\NormalTok{ NY,}
\NormalTok{    NV }\OperatorTok{=}\NormalTok{ NV,}
\NormalTok{    Y2 }\OperatorTok{=}\NormalTok{ Y2}
\NormalTok{)}

\CommentTok{\# Define model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ model(NY, NV, Y2):}
\NormalTok{    means }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(NY,), name }\OperatorTok{=} \StringTok{\textquotesingle{}means\textquotesingle{}}\NormalTok{)}
\NormalTok{    offset }\OperatorTok{=}\NormalTok{ bi.dist.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(NY,}\DecValTok{1}\NormalTok{), name }\OperatorTok{=} \StringTok{\textquotesingle{}offset\textquotesingle{}}\NormalTok{)}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{ bi.dist.exponential(}\DecValTok{1}\NormalTok{, shape}\OperatorTok{=}\NormalTok{(NY,), name }\OperatorTok{=} \StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{)}
\NormalTok{    sigma }\OperatorTok{=}\NormalTok{  numpyro.sample(}\StringTok{\textquotesingle{}sigma\textquotesingle{}}\NormalTok{, numpyro.distributions.Exponential(}\DecValTok{1}\NormalTok{).expand([NY])) }
\NormalTok{    tmp }\OperatorTok{=}\NormalTok{ jnp.tile(means, (NV, }\DecValTok{1}\NormalTok{)).reshape(NV,NY)  }
\NormalTok{    mu\_l }\OperatorTok{=}\NormalTok{ tmp }\OperatorTok{+}\NormalTok{ offset }
\NormalTok{    numpyro.sample(}\StringTok{\textquotesingle{}Y2\textquotesingle{}}\NormalTok{, Normal(mu\_l, jnp.tile(sigma, [NV, }\DecValTok{1}\NormalTok{])), obs}\OperatorTok{=}\NormalTok{Y2)}

\CommentTok{\# Run mcmc {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.run(model) }

\CommentTok{\# Summary {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{m.sampler.print\_summary(}\FloatTok{0.89}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-17}

We can express the Bayesian latent variable model using probability
distributions as follows:

\[
\begin{aligned}
& p(Y | X, Z, W, \sigma) = \text{Normal}(X * W + Z, \sigma^2) \\
& p(Z) = \text{Normal}(0, \tau^2) \\
& p(W) = \text{Normal}(0, \alpha^2) \\
\end{aligned}
\]

Where: - \emph{p(Y \textbar{} X, Z, W, \sigma)} is the likelihood
function for the observed outcome variable, which depends on both the
observed predictor \emph{X} and the latent variable \emph{Z}. -
\emph{p(Z)} is the prior distribution for the latent variable \emph{Z},
often modeled as \emph{Normal} with a mean of 0 and variance
\emph{\tau\^{}2}. - \emph{p(W)} is the prior distribution for the
regression coefficient(s) \emph{W}, typically assumed to follow a
\emph{Normal} distribution with mean 0 and variance \emph{\alpha\^{}2}.

The latent variable \emph{Z} introduces additional flexibility to the
model, capturing unobserved influences on the outcome \emph{Y}.

\section{Interpretation of Latent
Variables}\label{interpretation-of-latent-variables}

\begin{itemize}
\item
  \textbf{Latent Variable (\emph{Z})}: Represents hidden factors not
  captured by the observed variables, allowing the model to explain more
  of the variance in the outcome. For instance, in a psychological
  model, \emph{Z} might represent a latent trait such as intelligence or
  anxiety that influences the outcome.
\item
  \textbf{Posterior Inference}: The posterior distribution of the latent
  variable \emph{Z} can give insights into how much the unobserved
  factors contribute to the outcome.
\end{itemize}

\section{Use Cases}\label{use-cases}

\begin{itemize}
\tightlist
\item
  \textbf{Latent Factors in Psychometrics}: In psychometric models,
  latent variables represent traits or abilities that are not directly
  observed, such as cognitive ability or personality traits.
\item
  \textbf{Time-Varying Effects}: Latent variables can represent
  unobserved time trends or individual-specific effects in time-series
  or longitudinal models.
\item
  \textbf{Mixed Models}: In hierarchical or mixed models, latent
  variables can represent group-specific intercepts or slopes.
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Modeling Network}\label{modeling-network}

A network represents the relationships (links) between entities (nodes).
These links can be weighted (weighted network) or unweighted (binary
network), directed (directed network) or undirected (undirected
network). Regardless of their type, networks generate links shared by
nodes, leading to data dependency when modeling the network. One
proposed solution is to model network links with random
\href{12.\%20Varying\%20intercepts.qmd}{intercepts} and
\href{13.\%20Varying\%20slopes.qmd}{effects}. By adding such parameters
to the model, we can account for the correlations between node link
relationships.

\section{Considerations}\label{considerations-17}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\tightlist
\item
  The particularity here is that varying intercepts and slopes are
  generated for both \phantomsection\label{NodeF}{{nodal effects üõà}} and
  \phantomsection\label{DyadicF}{{dyadic effects üõà}}. Those the varying
  intercepts and slopes are identical to those described in previous
  chapters and will therefore not be detailed further and only the
  random centered version of the varying slopes will be described here.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-17}

Below is an example code snippet demonstrating Bayesian network model
with send-receiver effect:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Building model and sampling it {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{ids }\OperatorTok{=}\NormalTok{ jnp.arange(}\DecValTok{0}\NormalTok{,data[}\StringTok{\textquotesingle{}N\_id\textquotesingle{}}\NormalTok{][}\DecValTok{0}\NormalTok{])}
\NormalTok{idx }\OperatorTok{=}\NormalTok{ bi.net.vec\_node\_to\_edgle(jnp.stack([ids, ids], axis }\OperatorTok{=} \OperatorTok{{-}}\DecValTok{1}\NormalTok{))}

\AttributeTok{@jit}
\KeywordTok{def}\NormalTok{ logit(x):}
    \ControlFlowTok{return}\NormalTok{ jnp.log(x }\OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ x))}

\KeywordTok{def}\NormalTok{ model2(idx, result\_outcomes, dyad\_effects, focal\_individual\_predictors, target\_individual\_predictors):}
\NormalTok{    N\_id }\OperatorTok{=}\NormalTok{ ids.shape[}\DecValTok{0}\NormalTok{]}

    \CommentTok{\# Sender Receiver effect (SR) its shape is equal to N\_id {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
    \CommentTok{\#\# Varying intercept and slope for SR}
\NormalTok{    sr\_rf, sr\_raw, sr\_sigma, sr\_L }\OperatorTok{=}\NormalTok{ bi.net.nodes\_random\_effects(N\_id, cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{) }
\NormalTok{    sender\_receiver }\OperatorTok{=}\NormalTok{ sr\_rf}

    \CommentTok{\# Dyadic effect (D) its shape is equal to n dyads {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
    \CommentTok{\#\# Varying intercept and slope for D}
\NormalTok{    rf, dr\_raw, dr\_sigma, dr\_L }\OperatorTok{=}\NormalTok{ bi.net.dyadic\_random\_effects(sender\_receiver.shape[}\DecValTok{0}\NormalTok{], cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{)}
\NormalTok{    dr }\OperatorTok{=}\NormalTok{  rf}

\NormalTok{    lk(}\StringTok{\textquotesingle{}Y\textquotesingle{}}\NormalTok{, Poisson(jnp.exp( sender\_receiver }\OperatorTok{+}\NormalTok{ dr )), obs}\OperatorTok{=}\NormalTok{result\_outcomes)}

\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ idx,}
\NormalTok{    result\_outcomes }\OperatorTok{=}\NormalTok{ bi.net.mat\_to\_edgl(data[}\StringTok{\textquotesingle{}outcomes\textquotesingle{}}\NormalTok{]), }
\NormalTok{    dyad\_effects }\OperatorTok{=}\NormalTok{ bi.net.prepare\_dyadic\_effect(kinship), }\CommentTok{\# Can be a jax array of multiple dimensions}
\NormalTok{    focal\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{],}
\NormalTok{    target\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{]}
\NormalTok{)}

\NormalTok{m.run(model2) }
\NormalTok{summary }\OperatorTok{=}\NormalTok{ m.summary()}
\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-18}

\subsection{\texorpdfstring{\emph{Main
Formula}}{Main Formula}}\label{main-formula}

The simple model that can be built to model link weights between nodes
\emph{i} and \emph{j} can be defined using a poisson distribution:

\[
G_{ij} \sim Poisson(Y_{ij})
\]

\[
log(Y_{ij}) =  \lambda_i + \pi_j + \delta_{ij}
\]

where:

\begin{itemize}
\item
  \(Y\_{ij}\) is the weight of links between \emph{i} and \emph{j}.
\item
  \(\lambda_i\) is the \phantomsection\label{senderF}{{sender effect
  üõà}}.
\item
  \(\pi_j\) is the \phantomsection\label{receiverF}{{receiver effect
  üõà}}.
\item
  \(\delta_{ij}\) is the \phantomsection\label{DyadicF2}{{dyadic effect
  üõà}}.
\item ~
  \subsection{\texorpdfstring{\emph{Defining formula sub-equations and
  prior
  distributions}}{Defining formula sub-equations and prior distributions}}\label{defining-formula-sub-equations-and-prior-distributions}
\end{itemize}

\(\lambda_i\) and \(\pi_j\) are varying
\href{12.\%20Varying\%20intercepts.qmd}{intercepts} and
\href{13.\%20Varying\%20slopes.qmd}{slopes} identical to those described
in previous chapters and are define through the following equations:

\[
\left(\begin{array}{cc} 
\lambda_i \\
\pi_j 
\end{array}\right) 
\sim 
MultivariateNormal\left(\begin{array}{cc} 
\left(\begin{array}{cc} 
\sigma_\lambda \\
\sigma_\pi
\end{array}\right) \circ 
\left(\begin{array}{cc} 
L *
\left(\begin{array}{cc} 
\hat{\lambda}_i \\ \hat{\pi}_i
\end{array}\right)
\end{array}\right)
\end{array}\right)
\]

\[
\sigma_\lambda \sim Exponential(1)
\]

\[
\sigma_\pi \sim Exponential(1)
\]

\[
L \sim LKJ(2)
\]

Similarly, for each dyads we can define varying intercepts and slopes to
account for correlation between the propensity to emit and receive links
of a dyad :

\[
\left(\begin{array}{cc} 
\delta_{ij} \\
\delta_{ji}
\end{array}\right) 
\sim 
MultivariateNormal\left(\begin{array}{cc} 
\left(\begin{array}{cc} 
\sigma_\delta \\
\sigma_\delta
\end{array}\right) \circ 
\left(\begin{array}{cc} 
L_\delta *
\left(\begin{array}{cc} 
\hat{\delta}_{ij} \\ \hat{\delta}_{ji}
\end{array}\right)
\end{array}\right)
\end{array}\right)
\]

\[
\sigma_\delta \sim Exponential(1)
\]

\[
\sigma_\delta \sim Exponential(1)
\]

\[
L \sim LKJ(2)
\]

\section{Note(s)}\label{notes-9}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\tightlist
\item
  Note that any additional covariates can be summed with a regression
  coefficient to \(\lambda_i\), \(\pi_j\) and \(\delta_{ij}\). Of course
  for \(\lambda_i\), \(\pi_j\) as they represent nodal effects those
  covariates need to be nodal characteristics (e.g., sex, age) whereas
  for \(\\delta_{ij}\) as it represents dyadic effects those covariates
  need to be dyadic characteristics (e.g., genetic distances).
  Concidering previous example given a vector of nodal characteristics
  \emph{individual\_predictors} and a a matrix of dyadic characteristics
  \emph{kinship} we can incorporate those covariates in the
  sender-receiver effect and dyadic effect respectivelly as fellow:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ model2(idx, result\_outcomes, dyad\_effects, focal\_individual\_predictors, target\_individual\_predictors):}
\NormalTok{    N\_id }\OperatorTok{=}\NormalTok{ ids.shape[}\DecValTok{0}\NormalTok{]}

    \CommentTok{\# Sender Receiver effect (SR) its shape is equal to N\_id {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
    \CommentTok{\#\# Covariates for SR}
\NormalTok{    sr\_terms, focal\_effects, target\_effects }\OperatorTok{=}\NormalTok{ bi.net.nodes\_terms(focal\_individual\_predictors, target\_individual\_predictors) }

    \CommentTok{\#\# Varying intercept and slope for SR}
\NormalTok{    sr\_rf, sr\_raw, sr\_sigma, sr\_L }\OperatorTok{=}\NormalTok{ bi.net.nodes\_random\_effects(N\_id, cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{) }

\NormalTok{    sender\_receiver }\OperatorTok{=}\NormalTok{ sr\_terms }\OperatorTok{+}\NormalTok{ sr\_rf}

    \CommentTok{\# Dyadic effect (D) its shape is equal to n dyads {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
    \CommentTok{\#\# Covariates for D}
\NormalTok{    dr\_terms, dyad\_effects }\OperatorTok{=}\NormalTok{ bi.net.dyadic\_terms(dyad\_effects)}

    \CommentTok{\#\# Varying intercept and slope for D}
\NormalTok{    rf, dr\_raw, dr\_sigma, dr\_L }\OperatorTok{=}\NormalTok{ bi.net.dyadic\_random\_effects(sender\_receiver.shape[}\DecValTok{0}\NormalTok{], cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{)}
\NormalTok{    dr }\OperatorTok{=}\NormalTok{ dr\_terms }\OperatorTok{+}\NormalTok{ rf}

\NormalTok{    lk(}\StringTok{\textquotesingle{}Y\textquotesingle{}}\NormalTok{, Poisson(jnp.exp( sender\_receiver }\OperatorTok{+}\NormalTok{ dr ), is\_sparse }\OperatorTok{=} \VariableTok{False}\NormalTok{), obs}\OperatorTok{=}\NormalTok{result\_outcomes) }\CommentTok{\# is\_sparse = True, if matrix have a lot of zeros, it can help to speed up computation.}

\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ idx,}
\NormalTok{    result\_outcomes }\OperatorTok{=}\NormalTok{ bi.net.mat\_to\_edgl(data[}\StringTok{\textquotesingle{}outcomes\textquotesingle{}}\NormalTok{]), }
\NormalTok{    dyad\_effects }\OperatorTok{=}\NormalTok{ bi.net.prepare\_dyadic\_effect(kinship), }\CommentTok{\# Can be a jax array of multiple dimensions}
\NormalTok{    focal\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{],}
\NormalTok{    target\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{]}
\NormalTok{)}

\NormalTok{m.run(model2) }
\NormalTok{summary }\OperatorTok{=}\NormalTok{ m.summary()}
\NormalTok{summary.loc[[}\StringTok{\textquotesingle{}focal\_effects[0]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}target\_effects[0]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}dyad\_effects[0]\textquotesingle{}}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\item
  We can apply multiple variables similarly as
  \href{2.\%20Multiple\%20continuous\%20Variables.qmd}{chapter 2:
  Multiple continuous Variables}.
\item
  We can apply interaction terms similarly as
  \href{3.\%20Interaction\%20between\%20continuous\%20variables.qmd}{chapter
  3: Interaction between continuous variables}.
\item
  Network links can be modeled using Bernoulli, Binomial, Poisson, or
  zero-inflated Poisson distributions. So, by replacing the Poisson
  distribution with a binomial distribution, we can model the existence
  or absence of link --- i.e., model binary networks.
\item
  If the network is undirected, then accounting for correlation between
  propensity to emit and receive links is not necessary, and the terms
  \(\lambda_i\), \(\pi_j\) , and \(\delta_{ij}\) are no longer required.
  (Is it correct?)
\item
  In the following chapters, we will see how to incorporate additional
  network effects into the model to account for network structural
  properties (e.g., clusters, assortativity, triadic closure, etc.).
\end{itemize}

\end{tcolorbox}

\bookmarksetup{startatroot}

\chapter{Network with block model}\label{network-with-block-model}

Within networks, nodes can belong to different categories, and these
categories can potentially affect the propensity for node interactions.
For example, nodes can have different sex categories, and the propensity
to interact with nodes of the same sex can be higher than with nodes of
different sexes. To model the propensity for interaction between nodes
based on the categories they belong to, we can use a stochastic block
model approach.

\section{Considerations}\label{considerations-18}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\begin{itemize}
\tightlist
\item
  We consider predefined groups here, with the goal of evaluating the
  propensity for interaction between nodes within each group.
\item
  In addition to the block(s) model being tested, we need to include a
  block where all individuals are considered as belonging to the same
  group (\texttt{Any} in the example). This allows us to assess whether
  interaction tendencies differ between groups or if the propensity to
  interact is uniform across all individuals.
\end{itemize}

\end{tcolorbox}

\section{Example}\label{example-18}

Below is an example code snippet demonstrating a Bayesian network model
using the stochastic block model approach. The data is identical to the
\href{18.\%20Network\%20model.qmd}{Network model} example, with the
addition of covariates \emph{Any}, \emph{Merica}, and \emph{Quantum},
representing the block membership of each node.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ model3(idx, result\_outcomes, kinship, focal\_individual\_predictors, target\_individual\_predictors, Any, Merica, Quantum):}
\NormalTok{    N\_id }\OperatorTok{=}\NormalTok{ ids.shape[}\DecValTok{0}\NormalTok{]}

    \CommentTok{\# Block {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{    B\_any, b\_any, b\_ij\_any, b\_ii\_any }\OperatorTok{=}\NormalTok{ bi.net.block\_model(Any,}\DecValTok{1}\NormalTok{, name\_b\_ij }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ij\_Any\textquotesingle{}}\NormalTok{, name\_b\_ii }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ii\_Any\textquotesingle{}}\NormalTok{ )}
\NormalTok{    B\_Merica, b\_Merica, b\_ij\_Merica, b\_ii\_Merica }\OperatorTok{=}\NormalTok{ bi.net.block\_model(Merica,  }\DecValTok{3}\NormalTok{, name\_b\_ij }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ij\_Merica\textquotesingle{}}\NormalTok{, name\_b\_ii }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ii\_Merica\textquotesingle{}}\NormalTok{ )}
\NormalTok{    B\_Quantum, b\_Quantum, b\_ij\_Quantum, b\_ii\_Quantum }\OperatorTok{=}\NormalTok{ bi.net.block\_model(Quantum, }\DecValTok{2}\NormalTok{, name\_b\_ij }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ij\_Quantum\textquotesingle{}}\NormalTok{, name\_b\_ii }\OperatorTok{=} \StringTok{\textquotesingle{}b\_ii\_Quantum\textquotesingle{}}\NormalTok{ )}

    \CommentTok{\#\# SR {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\NormalTok{    sr\_terms, focal\_effects, target\_effects }\OperatorTok{=}\NormalTok{ bi.net.nodes\_terms(focal\_individual\_predictors, target\_individual\_predictors)}
\NormalTok{    sr\_rf, sr\_raw, sr\_sigma, sr\_L }\OperatorTok{=}\NormalTok{ bi.net.nodes\_random\_effects(sr\_terms.shape[}\DecValTok{0}\NormalTok{], cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{)}

\NormalTok{    sender }\OperatorTok{=}\NormalTok{ sr\_terms[idx[:,}\DecValTok{0}\NormalTok{],}\DecValTok{0}\NormalTok{] }\OperatorTok{+}\NormalTok{ sr\_terms[idx[:,}\DecValTok{1}\NormalTok{],}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ sr\_rf[idx[:,}\DecValTok{0}\NormalTok{],}\DecValTok{0}\NormalTok{]}
\NormalTok{    receiver }\OperatorTok{=}\NormalTok{  sr\_terms[idx[:,}\DecValTok{1}\NormalTok{],}\DecValTok{0}\NormalTok{] }\OperatorTok{+}\NormalTok{ sr\_terms[idx[:,}\DecValTok{0}\NormalTok{],}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\NormalTok{ sr\_rf[idx[:,}\DecValTok{1}\NormalTok{],}\DecValTok{1}\NormalTok{]}
\NormalTok{    sender\_receiver }\OperatorTok{=}\NormalTok{ jnp.stack([sender, receiver], axis }\OperatorTok{=} \DecValTok{1}\NormalTok{)}

    \CommentTok{\# Dyadic{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}  }
\NormalTok{    dr\_terms, dyad\_effects }\OperatorTok{=}\NormalTok{ bi.net.dyadic\_terms(kinship[:,}\DecValTok{0}\NormalTok{], kinship[:,}\DecValTok{1}\NormalTok{])}
\NormalTok{    rf, dr\_raw, dr\_sigma, dr\_L }\OperatorTok{=}\NormalTok{ bi.net.dyadic\_random\_effects(idx.shape[}\DecValTok{0}\NormalTok{], cholesky\_density }\OperatorTok{=} \DecValTok{2}\NormalTok{)}
\NormalTok{    dr }\OperatorTok{=}\NormalTok{ dr\_terms }\OperatorTok{+}\NormalTok{ rf}

\NormalTok{    lk(}\StringTok{\textquotesingle{}Y\textquotesingle{}}\NormalTok{, Poisson(jnp.exp(B\_any }\OperatorTok{+}\NormalTok{ B\_Merica }\OperatorTok{+}\NormalTok{ B\_Quantum }\OperatorTok{+}\NormalTok{ sender\_receiver }\OperatorTok{+}\NormalTok{ dr )), obs}\OperatorTok{=}\NormalTok{result\_outcomes)}

\NormalTok{m.data\_on\_model }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}
\NormalTok{    idx }\OperatorTok{=}\NormalTok{ idx,}
\NormalTok{    Any }\OperatorTok{=}\NormalTok{ Any}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }
\NormalTok{    Merica }\OperatorTok{=}\NormalTok{ Merica}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }
\NormalTok{    Quantum }\OperatorTok{=}\NormalTok{ Quantum}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}
\NormalTok{    result\_outcomes }\OperatorTok{=}\NormalTok{ bi.net.mat\_to\_edgl(data[}\StringTok{\textquotesingle{}outcomes\textquotesingle{}}\NormalTok{]), }
\NormalTok{    kinship }\OperatorTok{=}\NormalTok{ bi.net.mat\_to\_edgl(kinship),}
\NormalTok{    focal\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{],}
\NormalTok{    target\_individual\_predictors }\OperatorTok{=}\NormalTok{ data[}\StringTok{\textquotesingle{}individual\_predictors\textquotesingle{}}\NormalTok{]}
\NormalTok{)}

\NormalTok{m.run(model3) }
\NormalTok{summary }\OperatorTok{=}\NormalTok{ m.summary()}
\NormalTok{summary.loc[[}\StringTok{\textquotesingle{}focal\_effects[0]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}target\_effects[0]\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}dyad\_effects[0]\textquotesingle{}}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-19}

\subsection{\texorpdfstring{\emph{Main
Formula}}{Main Formula}}\label{main-formula-1}

The model's block structure can be represented by the following formula.
Note that the sender-receiver and dyadic effects are not represented
here, as they are already accounted for in the
\href{18.\%20Network\%20model.qmd}{Network model} chapter:

\[
G_{ij} \sim Poisson(Y_{ij})
\]

\[
log(Y_{ij}) =  B_{ij} + B_{ji}
\]

where:

\begin{itemize}
\tightlist
\item
  \(B_{ij}\) is the link probability between category \(i\) and \(j\).
\item
  \(B_{ji}\) is the link probability between category j to i.
\end{itemize}

\subsection{\texorpdfstring{\emph{Defining formula sub-equations and
prior
distributions}}{Defining formula sub-equations and prior distributions}}\label{defining-formula-sub-equations-and-prior-distributions-1}

To account for all link probabilities between categories, we can define
a square matrix \(B\) as follows: the off-diagonal elements represent
the link probabilities between categories \(i\) and \(j\), while the
diagonal elements represent the link probabilities between categories
\(i\) and \(j\).

\[
B_{i,j} = 
\begin{bmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,j} \\
a_{2,1} & a_{2,2} & \cdots & a_{2,j} \\
\vdots  & \vdots  & \ddots & \vdots  \\
a_{i,1} & a_{i,2} & \cdots & a_{i,j} 
\end{bmatrix}
\]

Where:

\begin{itemize}
\tightlist
\item
  \(B[i,j]\) is the link probability between category \(i\) and \(j\)
  when \(i \neq j\).
\item
  \(B[i,j]\) is the link probability within category \(i\) when
  \(i = j\).
\end{itemize}

As we concider link probability within categorioes to be higher to links
probabilites between categories we define different priors for the
diagonal and the off-diagonal. Priors should also depend on sample size,
N, so that the resultant network density approximates empirical
networks. Basic priors could be:

\[
\beta_{k \rightarrow k} \sim \text{Normal}\left(\text{Logit}\left(\frac{0.1}{\sqrt{N_k}}\right), 1.5\right)
\]

\[
\beta_{k \rightarrow \tilde{k}} \sim \text{Normal}\left(\text{Logit}\left(\frac{0.01}{0.5 \sqrt{N_k} + 0.5 \sqrt{N_{\tilde{k}}}}\right), 1.5\right)
\]

where :

\begin{itemize}
\tightlist
\item
  \(k \rightarrow k\) indicates a diagonal element.
\item
  \(k \rightarrow \tilde{k}\) indicates an off-diagonal element.
\end{itemize}

\section{Note(s)}\label{notes-10}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\item
  By defining this block model within our network model, we are
  estimating \phantomsection\label{assor}{{assortativity üõà}} and
  \phantomsection\label{disassor}{{disassortativity üõà}} for categorical
  variables.
\item
  Similarly, for continuous variables, we can generate a block model
  that includes all continuous variables.
\end{itemize}

\end{tcolorbox}

\bookmarksetup{startatroot}

\chapter{Modeling Network with control for data collection
biases}\label{modeling-network-with-control-for-data-collection-biases}

Data collection biases are a persistent issue in studies of social
networks. Two main types of biases can be considered:
\phantomsection\label{expoB}{{exposure biases üõà}} and
\phantomsection\label{censoB}{{censoring biases üõà}} .

To account for exposure biases, we can switch the network link
probability model from a \emph{Poisson} distribution to a
\emph{Binomial} distribution, as the binomial distribution allows us to
account for the number of trials for each data estimation.

To address censoring biases, we need to add an additional equation to
account for the probability of missing an interaction during observation
when modeling interaction between individual \emph{i} and \emph{j}.

\section{Considerations}\label{considerations-19}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example 1}\label{example-1-1}

Below is an example code snippet demonstrating Bayesian network model
with send-receiver effect, dyadic effect and block model effect while
accounting for exposure biases:

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Example2}\label{example2}

Below is an example code snippet demonstrating Bayesian network model
with send-receiver effect, dyadic effect and block model effect while
accounting for exposure biases and cesnsoring biases:

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-20}

\subsection{\texorpdfstring{\emph{Main
Formula}}{Main Formula}}\label{main-formula-2}

\[
\begin{align}
    Y_{[i,j]} &\sim \mathrm{Binomial}\Big(E_{[i,j]}, Q_{[i,j]}  \Big)
\end{align}
\]

\[
Q_{[i,j]} \in \{0,1\} 
\]

Where:

\begin{itemize}
\tightlist
\item
  \(E_{[i,j]}\) is the number of trials for each observation (i.e., the
  sampling effort).
\item
  \(Q_{[i,j]}\) is the indicator of a true tie between \(i\) and \(j\).
\end{itemize}

\[
\begin{aligned}
Q_{[i,j]} \sim \begin{cases} 
0 & \text{when no interactions occurs or when i or j are not detectable} \\
\text{1}  & \text{when i and j are both detectable}
\end{cases}
\end{aligned}
\]

\[
\begin{align}
  Q_{[i,j]}= \phi_{[i,j]}\eta_{[i]}\eta_{[j]}
\end{align}
\]

Where: - \(\phi_{[i,j]}\) is the probability of a true tie between \(i\)
and \(j\). - \(\eta_{[i]}\) is the probability of individual \(i\) being
detectable. - \(\eta_{[j]}\) is the probability of individual \(j\)
being detectable.

\subsection{\texorpdfstring{\emph{Defining formula sub-equations and
prior
distributions}}{Defining formula sub-equations and prior distributions}}\label{defining-formula-sub-equations-and-prior-distributions-2}

We can let \(\eta_{[i]}\) depend on individual-specific covariates. To
model the probability of censoring, we can model \(1-\eta_{[i]}\): \[
\text{logit}(1-\eta_{[i]}) = \mu_\psi + \hat\psi_{[i]}  \sigma_\psi + \ldots 
\]

where - \(\mu_\psi\) is an intercept - \(\sigma_\psi\) is a scalar for
the variance of random effects -
\(\hat\psi_{[i]}\sim \text {Normal}(0,1)\), and the ellipsis signifies
any linear model of coefficients and individual-level covariates. For
example, if \(C\) is an animal-specific measure, like a binary variable
for cryptic coloration, then the ellipsis may be replaced with:
\(\kappa_{[5]}C_{[i]}\), to give the effects of coloration on censoring
probability.

\section{Note(s)}\label{notes-11}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\begin{itemize}
\tightlist
\item
  One major limitation of this model is the necessity of having an
  estimation of the censoring bias for each individual.
\end{itemize}

\end{tcolorbox}

\bookmarksetup{startatroot}

\chapter{Network metrics}\label{network-metrics}

\section{General Principles}\label{general-principles-17}

\section{Considerations}\label{considerations-20}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-19}

Below is an example code snippet demonstrating Bayesian Network metrics
model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-21}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-10}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-10}

\section{Notes}\label{notes-12}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-16}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Multiplex network model}\label{multiplex-network-model}

\section{General Principles}\label{general-principles-18}

\section{Considerations}\label{considerations-21}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-20}

Below is an example code snippet demonstrating Bayesian Multiplex
network model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-22}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-11}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-11}

\section{Notes}\label{notes-13}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-17}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Multiplex temporal network
model}\label{multiplex-temporal-network-model}

\section{General Principles}\label{general-principles-19}

\section{Considerations}\label{considerations-22}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-21}

Below is an example code snippet demonstrating Bayesian Multiplex
temporal network model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-23}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-12}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-12}

\section{Notes}\label{notes-14}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-18}

McElreath (2018)

\bookmarksetup{startatroot}

\chapter{Multilayer Networks}\label{multilayer-networks}

\section{General Principles}\label{general-principles-20}

A multilayer network is a broader term that refers to networks composed
of multiple layers, where each layer may have its own set of nodes and
edges, potentially representing different types of entities and
interactions. This means the nodes can be the same or different across
layers.

\section{Considerations}\label{considerations-23}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-caution-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-caution-color!10!white, title=\textcolor{quarto-callout-caution-color}{\faFire}\hspace{0.5em}{Caution}, colback=white]

\end{tcolorbox}

\section{Example}\label{example-22}

Below is an example code snippet demonstrating Bayesian Multilayer
Networks model using the Bayesian Inference (BI) package:

\section{Python}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]

\end{Highlighting}
\end{Shaded}

\section{Mathematical Details}\label{mathematical-details-24}

\subsection{\texorpdfstring{\emph{Frequentist
formulation}}{Frequentist formulation}}\label{frequentist-formulation-13}

\subsection{\texorpdfstring{\emph{Bayesian
formulation}}{Bayesian formulation}}\label{bayesian-formulation-13}

\section{Notes}\label{notes-15}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, opacityback=0, titlerule=0mm, breakable, bottomrule=.15mm, colframe=quarto-callout-note-color-frame, arc=.35mm, coltitle=black, left=2mm, opacitybacktitle=0.6, leftrule=.75mm, toprule=.15mm, rightrule=.15mm, bottomtitle=1mm, colbacktitle=quarto-callout-note-color!10!white, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Note}, colback=white]

\end{tcolorbox}

\section{Reference(s)}\label{references-19}

McElreath (2018)

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-mcelreath2018statistical}
McElreath, Richard. 2018. \emph{Statistical Rethinking: A Bayesian
Course with Examples in r and Stan}. Chapman; Hall/CRC.

\end{CSLReferences}




\end{document}
